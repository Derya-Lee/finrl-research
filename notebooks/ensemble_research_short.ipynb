{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01b4dfb-4803-42a7-b1f3-5ac031746b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  copy of ensemble_research for less data to process \n",
    "ie. changed elements such as\n",
    "- tickers\n",
    "- turbulence_lookback and vol_lookback\n",
    "- start & end date\n",
    "- reduced training time ( which has the largest impact on processing time )\n",
    "- reduced validate and trading time\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from finrl.meta.preprocessor.binancedownloader import BinanceDownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c03aa70-1c21-4433-82c1-69eb38dba8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"SOLUSDT\", \"XRPUSDT\"]\n",
    "\n",
    "# file to import primary data \n",
    "ohlcv_file = \"binance_data_raw_example.csv\"\n",
    "\n",
    "# data source path\n",
    "notebook_path = Path().resolve()   \n",
    "current_dir = notebook_path.parent\n",
    "data_path = os.path.join(current_dir, \"data\")\n",
    "dt_raw_path = os.path.join(data_path, ohlcv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3bd115-1199-42c8-ac41-c7a16cf441be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw input data saved to...binance_data_raw_example.csv\n"
     ]
    }
   ],
   "source": [
    "# retrieve and save the primary ohlcv data\n",
    "\n",
    "bd = BinanceDownloader()\n",
    "df_raw = bd.download_multiple(ticker_list=tickers, start_str=\"1 Jan, 2018\")\n",
    "df_raw.to_csv(dt_raw_path, index=False)\n",
    "\n",
    "print(f\"raw input data saved to...{ohlcv_file}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f382cd7-8a8e-46ce-aae3-bfb03ac7ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR read\n",
    "df_raw = pd.read_csv(dt_raw_path, parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "763d3a22-0184-45e9-aa6a-af6d98729a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derya/finrl_research/notebooks/../finrl/utils/fear_and_greed.py:13: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
      "/home/derya/finrl_research/notebooks/../finrl/meta/preprocessor/preprocessors.py:176: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[\"fear_greed\"] = df[\"fear_greed\"].fillna(method=\"ffill\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed and saved input data for Exp.1, Exp.2, and Exp.3\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Process data for experiments, and store in data frames (df): \n",
    "Exp.1 control-group\n",
    "Exp.2 voltur-group - \n",
    "Exp.3 sen-group - \n",
    "\"\"\"\n",
    "from finrl.utils.rolling_windows import get_rolling_windows\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n",
    "\n",
    "df_raw = pd.read_csv(dt_raw_path, parse_dates=[\"date\"])\n",
    "\n",
    "proc_path = os.path.join(data_path, \"example_processed_bnc_data.csv\")\n",
    "proc_path_sentiment = os.path.join(data_path, \"example_sentiment_bnc_data.csv\")\n",
    "proc_path_voltur = os.path.join(data_path, \"example_voltur_bnc_data.csv\")\n",
    "\n",
    "\n",
    "# Exp.1 control-group \n",
    "fe = FeatureEngineer(use_technical_indicator=False)\n",
    "df_processed = fe.preprocess_data(df_raw)\n",
    "df_processed.to_csv(proc_path, index=False)\n",
    "\n",
    "# Exp.3 sen-group\n",
    "fe_sen = FeatureEngineer(use_technical_indicator=False, use_fear_greed=True)\n",
    "df_sen_processed = fe_sen.preprocess_data(df_raw)\n",
    "df_sen_processed.to_csv(proc_path_sentiment, index=False)\n",
    "\n",
    "# Exp.2 voltur-group\n",
    "from finrl.utils.calculate_turbulence_crypto import add_turbulence_and_volatility\n",
    "df_voltur_processed = add_turbulence_and_volatility(df_processed, turbulence_lookback=30, vol_lookback=30) \n",
    "df_voltur_processed.to_csv(proc_path_voltur, index=False)\n",
    "\n",
    "print(f\"processed and saved input data for Exp.1, Exp.2, and Exp.3\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61f2aaf-1fb4-4c8d-867d-fe0647636c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 8 rolling windows.\n",
      "Generated 8 rolling windows from 2024-05-04 to 2025-05-31.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Generate rolling windows \"\"\"\n",
    "\n",
    "TRAIN_START_DATE = \"2024-05-04\"  \n",
    "TRADE_END_DATE = \"2025-05-31\"\n",
    "\n",
    "start_date = pd.Timestamp(TRAIN_START_DATE)\n",
    "end_date = pd.Timestamp(TRADE_END_DATE)\n",
    "\n",
    "windows = get_rolling_windows(\n",
    "    train_months=3,\n",
    "    val_months=1,\n",
    "    trade_months=1,\n",
    "    start_date_str=start_date,\n",
    "    end_date_str=end_date,\n",
    "    next_rollings_months= 1,\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(windows)} rolling windows from {TRAIN_START_DATE} to {TRADE_END_DATE}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57972a22-f7d7-4c42-862f-1afccb32e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define Results (daily results) files \n",
    "Exp.1 control-group = account_values.csv\n",
    "Exp.2 voltur-group - sen_account_values.csv (sentiment_account_values)\n",
    "Exp.3 sen-group - ft_account_values.csv (featured_account_values)\n",
    "\"\"\"\n",
    "results_path = os.path.join(current_dir, \"results\")\n",
    "\n",
    "daily_accounts_path = os.path.join(results_path, \"example_account_values.csv\")\n",
    "sen_daily_accounts_path = os.path.join(results_path, \"example_sen_account_values.csv\")\n",
    "ft_daily_accounts_path = os.path.join(results_path, \"example_ft_account_values.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb829f97-1b18-4d9a-a11c-583ac8e41941",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "from finrl.config import model_configs\n",
    "\n",
    "PPO_model_kwargs = model_configs[\"PPO\"]\n",
    "A2C_model_kwargs = model_configs[\"A2C\"]\n",
    "DDPG_model_kwargs = model_configs[\"DDPG\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87d49f3d-10c4-4042-becf-26611c0abe6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for exp 0 is_featured:False\n",
      "for exp 0 is_sentiment:False\n",
      " Rolling window_1: 2024-05-04 to 2024-10-03\n",
      "[EVAL] Sharpe Debug: No volatility or insufficient data.\n",
      "✅ Window 1 Summary:\n",
      "  🔹 Train Dates : 2024-05-04 → 2024-08-03\n",
      "  🔹 Trade Dates : 2024-09-04 → 2024-10-03\n",
      "  🔹 Best Model  : PPO\n",
      "  🔹 Sharpe      : 0.45\n",
      " Rolling window_2: 2024-06-04 to 2024-11-03\n",
      "[EVAL] Sharpe Debug: No volatility or insufficient data.\n",
      "✅ Window 2 Summary:\n",
      "  🔹 Train Dates : 2024-06-04 → 2024-09-03\n",
      "  🔹 Trade Dates : 2024-10-04 → 2024-11-03\n",
      "  🔹 Best Model  : A2C\n",
      "  🔹 Sharpe      : 0.29\n",
      " Rolling window_3: 2024-07-04 to 2024-12-03\n",
      "[EVAL] Sharpe Debug: No volatility or insufficient data.\n",
      "✅ Window 3 Summary:\n",
      "  🔹 Train Dates : 2024-07-04 → 2024-10-03\n",
      "  🔹 Trade Dates : 2024-11-04 → 2024-12-03\n",
      "  🔹 Best Model  : PPO\n",
      "  🔹 Sharpe      : 0.48\n",
      " Rolling window_4: 2024-08-04 to 2025-01-03\n",
      "[EVAL] Sharpe Debug: No volatility or insufficient data.\n",
      "✅ Window 4 Summary:\n",
      "  🔹 Train Dates : 2024-08-04 → 2024-11-03\n",
      "  🔹 Trade Dates : 2024-12-04 → 2025-01-03\n",
      "  🔹 Best Model  : PPO\n",
      "  🔹 Sharpe      : 3.63\n",
      " Rolling window_5: 2024-09-04 to 2025-02-03\n",
      "✅ Window 5 Summary:\n",
      "  🔹 Train Dates : 2024-09-04 → 2024-12-03\n",
      "  🔹 Trade Dates : 2025-01-04 → 2025-02-03\n",
      "  🔹 Best Model  : A2C\n",
      "  🔹 Sharpe      : 1.11\n",
      " Rolling window_6: 2024-10-04 to 2025-03-03\n",
      "[EVAL] Sharpe Debug: No volatility or insufficient data.\n",
      "✅ Window 6 Summary:\n",
      "  🔹 Train Dates : 2024-10-04 → 2025-01-03\n",
      "  🔹 Trade Dates : 2025-02-04 → 2025-03-03\n",
      "  🔹 Best Model  : PPO\n",
      "  🔹 Sharpe      : 0.56\n",
      " Rolling window_7: 2024-11-04 to 2025-04-03\n",
      "✅ Window 7 Summary:\n",
      "  🔹 Train Dates : 2024-11-04 → 2025-02-03\n",
      "  🔹 Trade Dates : 2025-03-04 → 2025-04-03\n",
      "  🔹 Best Model  : DDPG\n",
      "  🔹 Sharpe      : 1.21\n",
      " Rolling window_8: 2024-12-04 to 2025-05-03\n",
      "✅ Window 8 Summary:\n",
      "  🔹 Train Dates : 2024-12-04 → 2025-03-03\n",
      "  🔹 Trade Dates : 2025-04-04 → 2025-05-03\n",
      "  🔹 Best Model  : PPO\n",
      "  🔹 Sharpe      : 0.40\n",
      "Daily account values saved to {'/home/derya/finrl_research/results/example_account_values.csv'}\n",
      "for exp 1 is_featured:True\n",
      "for exp 1 is_sentiment:False\n",
      " Rolling window_1: 2024-05-04 to 2024-10-03\n",
      "[EVAL] Sharpe Debug: No volatility or insufficient data.\n",
      "✅ Window 1 Summary:\n",
      "  🔹 Train Dates : 2024-05-04 → 2024-08-03\n",
      "  🔹 Trade Dates : 2024-09-04 → 2024-10-03\n",
      "  🔹 Best Model  : DDPG\n",
      "  🔹 Sharpe      : 1.36\n",
      " Rolling window_2: 2024-06-04 to 2024-11-03\n",
      "[EVAL] Sharpe Debug: No volatility or insufficient data.\n",
      "✅ Window 2 Summary:\n",
      "  🔹 Train Dates : 2024-06-04 → 2024-09-03\n",
      "  🔹 Trade Dates : 2024-10-04 → 2024-11-03\n",
      "  🔹 Best Model  : PPO\n",
      "  🔹 Sharpe      : 0.82\n",
      " Rolling window_3: 2024-07-04 to 2024-12-03\n",
      "✅ Window 3 Summary:\n",
      "  🔹 Train Dates : 2024-07-04 → 2024-10-03\n",
      "  🔹 Trade Dates : 2024-11-04 → 2024-12-03\n",
      "  🔹 Best Model  : PPO\n",
      "  🔹 Sharpe      : 0.48\n",
      " Rolling window_4: 2024-08-04 to 2025-01-03\n",
      "[EVAL] Sharpe Debug: No volatility or insufficient data.\n",
      "✅ Window 4 Summary:\n",
      "  🔹 Train Dates : 2024-08-04 → 2024-11-03\n",
      "  🔹 Trade Dates : 2024-12-04 → 2025-01-03\n",
      "  🔹 Best Model  : A2C\n",
      "  🔹 Sharpe      : 3.51\n",
      " Rolling window_5: 2024-09-04 to 2025-02-03\n",
      "✅ Window 5 Summary:\n",
      "  🔹 Train Dates : 2024-09-04 → 2024-12-03\n",
      "  🔹 Trade Dates : 2025-01-04 → 2025-02-03\n",
      "  🔹 Best Model  : A2C\n",
      "  🔹 Sharpe      : 1.15\n",
      " Rolling window_6: 2024-10-04 to 2025-03-03\n",
      "✅ Window 6 Summary:\n",
      "  🔹 Train Dates : 2024-10-04 → 2025-01-03\n",
      "  🔹 Trade Dates : 2025-02-04 → 2025-03-03\n",
      "  🔹 Best Model  : DDPG\n",
      "  🔹 Sharpe      : 0.60\n",
      " Rolling window_7: 2024-11-04 to 2025-04-03\n",
      "✅ Window 7 Summary:\n",
      "  🔹 Train Dates : 2024-11-04 → 2025-02-03\n",
      "  🔹 Trade Dates : 2025-03-04 → 2025-04-03\n",
      "  🔹 Best Model  : DDPG\n",
      "  🔹 Sharpe      : 1.21\n",
      " Rolling window_8: 2024-12-04 to 2025-05-03\n",
      "✅ Window 8 Summary:\n",
      "  🔹 Train Dates : 2024-12-04 → 2025-03-03\n",
      "  🔹 Trade Dates : 2025-04-04 → 2025-05-03\n",
      "  🔹 Best Model  : A2C\n",
      "  🔹 Sharpe      : 0.33\n",
      "Daily account values saved to {'/home/derya/finrl_research/results/example_ft_account_values.csv'}\n",
      "for exp 2 is_featured:False\n",
      "for exp 2 is_sentiment:True\n",
      " Rolling window_1: 2024-05-04 to 2024-10-03\n",
      "✅ Window 1 Summary:\n",
      "  🔹 Train Dates : 2024-05-04 → 2024-08-03\n",
      "  🔹 Trade Dates : 2024-09-04 → 2024-10-03\n",
      "  🔹 Best Model  : DDPG\n",
      "  🔹 Sharpe      : 1.36\n",
      " Rolling window_2: 2024-06-04 to 2024-11-03\n",
      "✅ Window 2 Summary:\n",
      "  🔹 Train Dates : 2024-06-04 → 2024-09-03\n",
      "  🔹 Trade Dates : 2024-10-04 → 2024-11-03\n",
      "  🔹 Best Model  : DDPG\n",
      "  🔹 Sharpe      : 0.82\n",
      " Rolling window_3: 2024-07-04 to 2024-12-03\n",
      "[EVAL] Sharpe Debug: No volatility or insufficient data.\n",
      "✅ Window 3 Summary:\n",
      "  🔹 Train Dates : 2024-07-04 → 2024-10-03\n",
      "  🔹 Trade Dates : 2024-11-04 → 2024-12-03\n",
      "  🔹 Best Model  : PPO\n",
      "  🔹 Sharpe      : 0.35\n",
      " Rolling window_4: 2024-08-04 to 2025-01-03\n",
      "[EVAL] Sharpe Debug: No volatility or insufficient data.\n",
      "✅ Window 4 Summary:\n",
      "  🔹 Train Dates : 2024-08-04 → 2024-11-03\n",
      "  🔹 Trade Dates : 2024-12-04 → 2025-01-03\n",
      "  🔹 Best Model  : PPO\n",
      "  🔹 Sharpe      : 3.66\n",
      " Rolling window_5: 2024-09-04 to 2025-02-03\n",
      "✅ Window 5 Summary:\n",
      "  🔹 Train Dates : 2024-09-04 → 2024-12-03\n",
      "  🔹 Trade Dates : 2025-01-04 → 2025-02-03\n",
      "  🔹 Best Model  : PPO\n",
      "  🔹 Sharpe      : 1.11\n",
      " Rolling window_6: 2024-10-04 to 2025-03-03\n",
      "[EVAL] Sharpe Debug: No volatility or insufficient data.\n",
      "✅ Window 6 Summary:\n",
      "  🔹 Train Dates : 2024-10-04 → 2025-01-03\n",
      "  🔹 Trade Dates : 2025-02-04 → 2025-03-03\n",
      "  🔹 Best Model  : A2C\n",
      "  🔹 Sharpe      : 0.55\n",
      " Rolling window_7: 2024-11-04 to 2025-04-03\n",
      "✅ Window 7 Summary:\n",
      "  🔹 Train Dates : 2024-11-04 → 2025-02-03\n",
      "  🔹 Trade Dates : 2025-03-04 → 2025-04-03\n",
      "  🔹 Best Model  : DDPG\n",
      "  🔹 Sharpe      : 1.21\n",
      " Rolling window_8: 2024-12-04 to 2025-05-03\n",
      "✅ Window 8 Summary:\n",
      "  🔹 Train Dates : 2024-12-04 → 2025-03-03\n",
      "  🔹 Trade Dates : 2025-04-04 → 2025-05-03\n",
      "  🔹 Best Model  : PPO\n",
      "  🔹 Sharpe      : 0.42\n",
      "Daily account values saved to {'/home/derya/finrl_research/results/example_sen_account_values.csv'}\n"
     ]
    }
   ],
   "source": [
    "from finrl.utils.compute_sharpe_metrics import compute_sharpe_metrics\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from finrl.meta.preprocessor.preprocessors import data_split\n",
    "from finrl.meta.env_crypto_trading.env_cryptotrading import CryptoTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "import numpy as np\n",
    "\n",
    "experiments = [\n",
    "   {\"df\": df_processed, \"result_fl\": daily_accounts_path, \"featured\":False, \"sentiment\":False},\n",
    "   {\"df\": df_voltur_processed, \"result_fl\": ft_daily_accounts_path, \"featured\":True, \"sentiment\":False},\n",
    "   {\"df\": df_sen_processed, \"result_fl\": sen_daily_accounts_path, \"featured\":False, \"sentiment\":True}\n",
    "]\n",
    "\n",
    "# for each experiment\n",
    "for j, exp in enumerate(experiments):\n",
    "\n",
    "    # reset experiement's results data frame\n",
    "    account_values_df =  pd.DataFrame()\n",
    "    \n",
    "  #  exp = experiments[j]\n",
    "    input_data = exp[\"df\"]\n",
    "    results_fl = exp[\"result_fl\"] \n",
    "    is_featured = exp[\"featured\"]\n",
    "    is_sentiment =  exp[\"sentiment\"]\n",
    "\n",
    "    # for each window 1 to 22\n",
    "    for i, (train_start, train_end, val_start, val_end, trade_start, trade_end) in enumerate(windows):\n",
    "        \n",
    "        # split data for training, validation and testing (trade)\n",
    "        train_data = data_split(input_data, train_start, train_end)\n",
    "        val_data = data_split(input_data, val_start, val_end)\n",
    "        trade_data = data_split(input_data, trade_start, trade_end)\n",
    "\n",
    "        window_name = f\"window_{i+1}\"\n",
    "        print(f\" Rolling {window_name}: {train_start.date()} to {trade_end.date()}\")\n",
    "        \n",
    "        # Train all 3 models\n",
    "        env_train = DummyVecEnv([lambda: CryptoTradingEnv(train_data, featured=is_featured, sentiment=is_sentiment)])\n",
    "        agent = DRLAgent(env=env_train)\n",
    "    \n",
    "        models = {\n",
    "            \"ppo\": agent.train_PPO(total_timesteps=len(train_data)*30, model_kwargs=PPO_model_kwargs),\n",
    "            \"a2c\": agent.train_A2C(total_timesteps=len(train_data)*30, model_kwargs=A2C_model_kwargs),\n",
    "            \"ddpg\": agent.train_DDPG(total_timesteps=int(len(train_data)*30*0.5), model_kwargs=DDPG_model_kwargs)\n",
    "        }\n",
    "    \n",
    "        #----------------------------------------------------------------------------------------------------------------------\n",
    "        # Validation : Select best model based on sharp produced during validation\n",
    "        # Note: daily trading results, ie dates, account value, daily return etc are not recorded during validation\n",
    "        # only sharp is calculated to select the best model\n",
    "        #----------------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        best_model = None\n",
    "        best_sharpe = -np.inf\n",
    "        val_sharpes = []\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            \n",
    "            env_val = DummyVecEnv([lambda: CryptoTradingEnv(val_data, featured=is_featured, sentiment=is_sentiment)])\n",
    "            sharpe_metrics = DRLAgent.DRL_evaluation(model=model, environment=env_val)\n",
    "            sharpe = sharpe_metrics[\"sharpe\"]\n",
    "            val_sharpes.append({\"name\": name, \"sharpe\": sharpe})\n",
    "    \n",
    "            if not np.isnan(sharpe) and sharpe > best_sharpe:\n",
    "                best_model = model\n",
    "                best_sharpe = sharpe    \n",
    "    \n",
    "        #----------------------------------------------------------------------------------------------------------------------\n",
    "        # Trade using the best model, record results  \n",
    "        # basic data (for control) recorded daily includes:   \"date\",  \"account_value\", \"daily_return\", \"daily_volatility\" \n",
    "        #----------------------------------------------------------------------------------------------------------------------\n",
    "               \n",
    "        if best_model is not None:\n",
    "            env_trade = DummyVecEnv([lambda: CryptoTradingEnv(trade_data, featured=is_featured, sentiment=is_sentiment)])\n",
    "\n",
    "            startdt = pd.to_datetime(trade_start)\n",
    "            env_trade.envs[0].trading_mode = True\n",
    "            df_result = DRLAgent.DRL_prediction(model=best_model, environment=env_trade, start_date=startdt)\n",
    "\n",
    "            df_result[\"window\"] = i + 1\n",
    "\n",
    "             # concat for reporting\n",
    "            if \"account_values_df\" not in locals():\n",
    "                account_values_df = df_result.copy()\n",
    "            else:\n",
    "                account_values_df = pd.concat([account_values_df, df_result], ignore_index=True)\n",
    "          \n",
    "        else:\n",
    "            print(f\"❌ No valid model selected in window {i+1} — skipping trade step.\")\n",
    "\n",
    "            #  --- Trade End ---\n",
    "    \n",
    "        print(f\"✅ Window {i+1} Summary:\")\n",
    "        print(f\"  🔹 Train Dates : {train_start.date()} → {train_end.date()}\")\n",
    "        print(f\"  🔹 Trade Dates : {trade_start.date()} → {trade_end.date()}\")\n",
    "        print(f\"  🔹 Best Model  : {best_model.__class__.__name__ if best_model else 'None'}\")\n",
    "        print(f\"  🔹 Sharpe      : {best_sharpe:.2f}\")\n",
    "\n",
    "\n",
    "    \n",
    "    # get daily performence file name for the experiment j and save to dedicated location\n",
    "     \n",
    "    account_values_df.to_csv(results_fl, index=False)\n",
    "    print(f\"Daily account values saved to\", {results_fl})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71baa896-b3a6-4e27-9a02-4720b541521a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
