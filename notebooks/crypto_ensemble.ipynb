{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cc77353-a99f-4823-b81b-41c88462d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Reinforcement Learning for Automated Stock Trading – for Crypto\n",
    "\n",
    "### 📊 Summary of Crypto DRL Ensemble Trading\n",
    "\n",
    "# This notebook implements a deep reinforcement learning ensemble strategy adapted from the ICAIF 2020 paper, applied to cryptocurrency trading.\n",
    "\n",
    "#- **Assets Used**: BTC, ETH, BNB, XRP\n",
    "#- **Time Period**: 2018 to 2024, with rolling windows\n",
    "#- **Agents Used**: PPO, A2C, DDPG (Stable-Baselines3)\n",
    "#- **Strategy**:\n",
    "#  - Train each agent on a rolling window (e.g. 6 months)\n",
    "#   - Validate on 2 months of unseen data\n",
    "#   - Select the model with the highest Sharpe ratio\n",
    "#   - Trade using the best model for 2 months\n",
    "# - **Objective**: Observe the effectiveness of the agents using the ensemble strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e157d9-cf01-4ade-8969-f0467ca04c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# FinRL modules\n",
    "# from finrl.config_tickers import DOW_30_TICKER\n",
    "# from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.binancedownloader import BinanceDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_crypto_trading.env_cryptotrading import CryptoTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "# from finrl.agents.stablebaselines3.models import DRLEnsembleAgent\n",
    "from finrl.plot.plot import backtest_plot, get_daily_return, get_baseline\n",
    "from finrl.plot.plot import backtest_stats_qs as backtest_stats  # using QuantStats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08168239-2ea4-49f9-8f2c-96565120e0e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading Binance data from local cache...\n",
      "Data saved to: ../data/binance_less_raw.csv\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "from finrl.config import (TRAIN_START_DATE, TRAIN_END_DATE, TEST_START_DATE, TEST_END_DATE, TRADE_START_DATE, TRADE_END_DATE)\n",
    "\n",
    "START_DATE = TRAIN_START_DATE \n",
    "END_DATE =  TRADE_END_DATE\n",
    "\n",
    "TRAIN_WINDOW_MONTHS = 6\n",
    "VALIDATION_WINDOW_MONTHS = 2\n",
    "TRADE_WINDOW_MONTHS = 2\n",
    "\n",
    "# data_path = \"../data/binance_raw.csv\"\n",
    "data_path = \"../data/binance_less_raw.csv\"\n",
    "\n",
    "# if os.path.exists(data_path):\n",
    "#     print(\" Loading Binance data from local cache...\")\n",
    "#     df_raw = pd.read_csv(data_path, parse_dates=[\"date\"])\n",
    "#     print(\"Data saved to:\", data_path)\n",
    "# else:\n",
    "#     print(\" Downloading fresh Binance data...\")\n",
    "#     # tickers = [\"BTCUSDT\", \"ETHUSDT\", \"BNBUSDT\", \"SOLUSDT\", \"XRPUSDT\"]\n",
    "#     tickers = [\"BTCUSDT\", \"ETHUSDT\", \"BNBUSDT\", \"XRPUSDT\"]\n",
    "#     bd = BinanceDownloader()\n",
    "df_raw = bd.download_multiple(ticker_list=tickers, start_str=\"1 Jan, 2012\")\n",
    "df_raw.to_csv(data_path, index=False)\n",
    "print(\"Data retrieved from:\", data_path)\n",
    "\n",
    "print(\"Done...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b1477ba-0f47-4600-97e6-f30bbc2d9517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tic\n",
       "BNB-USD   2017-11-06\n",
       "BTC-USD   2017-08-17\n",
       "ETH-USD   2017-08-17\n",
       "XRP-USD   2018-05-04\n",
       "Name: date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.groupby(\"tic\")[\"date\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf5ab53-333a-4c5e-b22e-301b5bced827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# df_raw = YahooDownloader(start_date=TRAIN_START_DATE,\n",
    "#                          end_date=TRADE_END_DATE,\n",
    "#                          ticker_list=ticker_list).fetch_data()\n",
    "\n",
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     tech_indicator_list=[\"macd\", \"rsi_30\", \"cci_30\"], \n",
    "                     use_vix=False,\n",
    "                     use_turbulence=True\n",
    "                     )\n",
    "\n",
    "# user_defined_feature=False\n",
    "\n",
    "df_processed = fe.preprocess_data(df_raw)  # D: removed processing from original\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7d41cd8-358a-4691-a2d3-6adb3138bcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Created 17 rolling windows.\n",
      "Generated 17 rolling windows from 2020-01-06 to 2024-12-26.\n"
     ]
    }
   ],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from finrl.utils.rolling_windows import get_rolling_windows\n",
    "\n",
    "# PPO: Good for stable exploration with large batches\n",
    "# A2C: Low n_steps means quick updates (crypto works well with this)\n",
    "# DDPG: Buffer and batch sizes are fine; could experiment with larger buffer_size if needed\n",
    "\n",
    "A2C_model_kwargs = {\n",
    "    'n_steps': 5,\n",
    "    'ent_coef': 0.005,\n",
    "    'learning_rate': 0.0007\n",
    "}\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "    'ent_coef': 0.01,\n",
    "    'n_steps': 2048,\n",
    "    'learning_rate': 0.00025,\n",
    "    'batch_size': 128\n",
    "}\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "    'buffer_size': 10000,\n",
    "    'learning_rate': 0.0005,\n",
    "    'batch_size': 64\n",
    "}\n",
    "\n",
    "TRAIN_WINDOW_MONTHS = 6\n",
    "VALIDATION_WINDOW_MONTHS = 2\n",
    "TRADE_WINDOW_MONTHS = 2\n",
    "\n",
    "# windows = get_rolling_windows(\n",
    "#     train_months=TRAIN_WINDOW_MONTHS,\n",
    "#     val_months=VALIDATION_WINDOW_MONTHS,\n",
    "#     trade_months=TRADE_WINDOW_MONTHS\n",
    "# )\n",
    "\n",
    "windows = get_rolling_windows(\n",
    "    train_months=TRAIN_WINDOW_MONTHS,\n",
    "    val_months=VALIDATION_WINDOW_MONTHS,\n",
    "    trade_months=TRADE_WINDOW_MONTHS,\n",
    "    start_date_str=TRAIN_START_DATE,\n",
    "    end_date_str=TRADE_END_DATE\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Generated {len(windows)} rolling windows from {TRAIN_START_DATE} to {TRADE_END_DATE}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc10bde6-30fa-414d-b659-1a26f61e2893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rolling window_1: 2020-01-06 to 2020-11-06\n",
      " Window 1\n",
      "  Train window: 2020-01-06 to 2020-07-06 — 182 days\n",
      "  Val window  : 2020-07-07 to 2020-09-06   — 61 days\n",
      "  Trade window: 2020-09-07 to 2020-11-06 — 60 days\n",
      "count    60.000000\n",
      "mean      0.002093\n",
      "std       0.028938\n",
      "min      -0.110398\n",
      "25%      -0.006764\n",
      "50%       0.003292\n",
      "75%       0.017492\n",
      "max       0.108308\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1310 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1188         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023009672 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0010114312 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.9         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 77.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1057         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020263405 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.0046268106 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.5         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 65.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1017         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036886567 |\n",
      "|    clip_fraction        | 0.0486       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.014409006  |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 47.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 983           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 10            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074817543 |\n",
      "|    clip_fraction        | 0.000928      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.85         |\n",
      "|    explained_variance   | 0.007356763   |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 43            |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00111      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 77.8          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1002        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004490881 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.011380076 |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.6        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 83.2        |\n",
      "-----------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 0.08 | Asset: 1,000,753.61\n",
      "[Validation] Step 2 | Reward: -1.66 | Asset: 983,365.99\n",
      "[Validation] Step 3 | Reward: -1.68 | Asset: 983,188.69\n",
      "[Validation] Step 4 | Reward: -2.07 | Asset: 979,333.08\n",
      "[Validation] Step 5 | Reward: -1.30 | Asset: 987,029.01\n",
      "[Validation] Step 57 | Reward: 6.58 | Asset: 1,065,838.79\n",
      "[Validation] Step 58 | Reward: -5.32 | Asset: 946,776.01\n",
      "[Validation] Step 59 | Reward: -2.65 | Asset: 973,501.12\n",
      "[Validation] Step 60 | Reward: -6.19 | Asset: 938,134.28\n",
      "[Validation] Step 61 | Reward: -6.19 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(1065838.7880694692), np.float64(946776.0059459799), np.float64(973501.117330486), np.float64(938134.2802902715), 1000000.0]\n",
      "[DEBUG] total reward: -6.186572529375553\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 1.78 | Asset: 1,017,774.43\n",
      "[Validation] Step 2 | Reward: -0.41 | Asset: 995,940.91\n",
      "[Validation] Step 3 | Reward: 0.19 | Asset: 1,001,913.41\n",
      "[Validation] Step 4 | Reward: -0.40 | Asset: 996,034.51\n",
      "[Validation] Step 5 | Reward: 0.35 | Asset: 1,003,504.56\n",
      "[Validation] Step 57 | Reward: 17.04 | Asset: 1,170,371.95\n",
      "[Validation] Step 58 | Reward: 3.93 | Asset: 1,039,349.13\n",
      "[Validation] Step 59 | Reward: 6.85 | Asset: 1,068,479.59\n",
      "[Validation] Step 60 | Reward: 2.86 | Asset: 1,028,556.71\n",
      "[Validation] Step 61 | Reward: 2.86 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(1170371.9518768531), np.float64(1039349.1348775799), np.float64(1068479.591339553), np.float64(1028556.7142905885), 1000000.0]\n",
      "[DEBUG] total reward: 2.8556707464158535\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 2 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 3 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 4 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 5 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 57 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 58 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 59 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 60 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 61 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(1000000.0), np.float64(1000000.0), np.float64(1000000.0), np.float64(1000000.0), 1000000.0]\n",
      "[DEBUG] total reward: 0.0\n",
      "[EVAL] Sharpe Debug: No volatility or insufficient data.\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[TRADE] Step 2 | Reward: 0.90 | Asset: 1,008,970.66\n",
      "[TRADE] Step 3 | Reward: 1.77 | Asset: 1,017,733.57\n",
      "[TRADE] Step 4 | Reward: 2.30 | Asset: 1,023,035.40\n",
      "[TRADE] Step 5 | Reward: 2.91 | Asset: 1,029,116.98\n",
      "[TRADE] Step 56 | Reward: 22.47 | Asset: 1,224,725.93\n",
      "[TRADE] Step 57 | Reward: 26.59 | Asset: 1,265,880.13\n",
      "[TRADE] Step 58 | Reward: 27.65 | Asset: 1,276,545.92\n",
      "[TRADE] Step 59 | Reward: 28.13 | Asset: 1,281,342.15\n",
      "[TRADE] Step 60 | Reward: 28.13 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1224725.9251363005), np.float64(1265880.1274920283), np.float64(1276545.9217209325), np.float64(1281342.1460371804), 1000000.0]\n",
      "[DEBUG] total reward: 28.13421457936056\n",
      "✅ Best model: PPO with Sharpe 0.1818\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                   NaN\n",
      "1970-01-01 00:00:00.000000001+00:00    0.008971\n",
      "1970-01-01 00:00:00.000000002+00:00    0.008685\n",
      "1970-01-01 00:00:00.000000003+00:00    0.005209\n",
      "1970-01-01 00:00:00.000000004+00:00    0.005945\n",
      "1970-01-01 00:00:00.000000005+00:00   -0.011692\n",
      "1970-01-01 00:00:00.000000006+00:00    0.019507\n",
      "1970-01-01 00:00:00.000000007+00:00    0.001087\n",
      "1970-01-01 00:00:00.000000008+00:00    0.014272\n",
      "1970-01-01 00:00:00.000000009+00:00    0.004225\n",
      "1970-01-01 00:00:00.000000010+00:00   -0.001654\n",
      "1970-01-01 00:00:00.000000011+00:00    0.012495\n",
      "1970-01-01 00:00:00.000000012+00:00   -0.015884\n",
      "1970-01-01 00:00:00.000000013+00:00   -0.045834\n",
      "1970-01-01 00:00:00.000000014+00:00    0.000939\n",
      "1970-01-01 00:00:00.000000015+00:00   -0.030481\n",
      "1970-01-01 00:00:00.000000016+00:00    0.020952\n",
      "1970-01-01 00:00:00.000000017+00:00    0.000573\n",
      "1970-01-01 00:00:00.000000018+00:00    0.003964\n",
      "1970-01-01 00:00:00.000000019+00:00    0.004471\n",
      "1970-01-01 00:00:00.000000020+00:00   -0.007396\n",
      "1970-01-01 00:00:00.000000021+00:00    0.000218\n",
      "1970-01-01 00:00:00.000000022+00:00   -0.000002\n",
      "1970-01-01 00:00:00.000000023+00:00   -0.014643\n",
      "1970-01-01 00:00:00.000000024+00:00   -0.004657\n",
      "1970-01-01 00:00:00.000000025+00:00   -0.002669\n",
      "1970-01-01 00:00:00.000000026+00:00    0.011841\n",
      "1970-01-01 00:00:00.000000027+00:00    0.011050\n",
      "1970-01-01 00:00:00.000000028+00:00   -0.014655\n",
      "1970-01-01 00:00:00.000000029+00:00   -0.000026\n",
      "1970-01-01 00:00:00.000000030+00:00    0.007441\n",
      "1970-01-01 00:00:00.000000031+00:00    0.010640\n",
      "1970-01-01 00:00:00.000000032+00:00    0.021485\n",
      "1970-01-01 00:00:00.000000033+00:00    0.000743\n",
      "1970-01-01 00:00:00.000000034+00:00    0.014187\n",
      "1970-01-01 00:00:00.000000035+00:00   -0.000100\n",
      "1970-01-01 00:00:00.000000036+00:00   -0.000230\n",
      "1970-01-01 00:00:00.000000037+00:00   -0.000206\n",
      "1970-01-01 00:00:00.000000038+00:00   -0.002447\n",
      "1970-01-01 00:00:00.000000039+00:00    0.002363\n",
      "1970-01-01 00:00:00.000000040+00:00    0.003816\n",
      "1970-01-01 00:00:00.000000041+00:00    0.008279\n",
      "1970-01-01 00:00:00.000000042+00:00    0.007184\n",
      "1970-01-01 00:00:00.000000043+00:00    0.069377\n",
      "1970-01-01 00:00:00.000000044+00:00    0.020384\n",
      "1970-01-01 00:00:00.000000045+00:00   -0.003692\n",
      "1970-01-01 00:00:00.000000046+00:00    0.013966\n",
      "1970-01-01 00:00:00.000000047+00:00   -0.006808\n",
      "1970-01-01 00:00:00.000000048+00:00   -0.000091\n",
      "1970-01-01 00:00:00.000000049+00:00    0.043751\n",
      "1970-01-01 00:00:00.000000050+00:00   -0.004362\n",
      "1970-01-01 00:00:00.000000051+00:00    0.013622\n",
      "1970-01-01 00:00:00.000000052+00:00   -0.000841\n",
      "1970-01-01 00:00:00.000000053+00:00    0.012822\n",
      "1970-01-01 00:00:00.000000054+00:00    0.000054\n",
      "1970-01-01 00:00:00.000000055+00:00   -0.006320\n",
      "1970-01-01 00:00:00.000000056+00:00    0.033603\n",
      "1970-01-01 00:00:00.000000057+00:00    0.008426\n",
      "1970-01-01 00:00:00.000000058+00:00    0.003757\n",
      "1970-01-01 00:00:00.000000059+00:00   -0.219568\n",
      "Name: daily_return, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: 0.00061\n",
      "   Std return : 0.03318\n",
      "   Sharpe     : 0.29235\n",
      " Rolling window_2: 2020-04-06 to 2021-02-06\n",
      " Window 2\n",
      "  Train window: 2020-04-06 to 2020-10-06 — 183 days\n",
      "  Val window  : 2020-10-07 to 2020-12-06   — 60 days\n",
      "  Trade window: 2020-12-07 to 2021-02-06 — 61 days\n",
      "count    59.000000\n",
      "mean      0.010415\n",
      "std       0.030858\n",
      "min      -0.083952\n",
      "25%      -0.002678\n",
      "50%       0.007306\n",
      "75%       0.024891\n",
      "max       0.100382\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1385 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1170         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031882788 |\n",
      "|    clip_fraction        | 0.0339       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | -0.028492332 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1142         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005433974  |\n",
      "|    clip_fraction        | 0.0493       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0006533861 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 42.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1095         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043052523 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.01203239   |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1101         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020703194 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.00868541   |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.000789    |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 49.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1072         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022421724 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.02452749   |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00098     |\n",
      "|    std                  | 0.99         |\n",
      "|    value_loss           | 52.5         |\n",
      "------------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 1.58 | Asset: 1,015,783.61\n",
      "[Validation] Step 2 | Reward: 1.69 | Asset: 1,016,874.30\n",
      "[Validation] Step 3 | Reward: 1.72 | Asset: 1,017,178.99\n",
      "[Validation] Step 4 | Reward: 1.73 | Asset: 1,017,319.78\n",
      "[Validation] Step 5 | Reward: 3.18 | Asset: 1,031,773.32\n",
      "[Validation] Step 56 | Reward: 29.94 | Asset: 1,299,439.32\n",
      "[Validation] Step 57 | Reward: 31.73 | Asset: 1,317,295.20\n",
      "[Validation] Step 58 | Reward: 26.23 | Asset: 1,262,320.86\n",
      "[Validation] Step 59 | Reward: 29.89 | Asset: 1,298,854.22\n",
      "[Validation] Step 60 | Reward: 29.89 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1299439.3200528205), np.float64(1317295.204136366), np.float64(1262320.856653708), np.float64(1298854.2150241535), 1000000.0]\n",
      "[DEBUG] total reward: 29.885422077961266\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 2.40 | Asset: 1,024,004.54\n",
      "[Validation] Step 2 | Reward: 3.56 | Asset: 1,035,636.05\n",
      "[Validation] Step 3 | Reward: 5.82 | Asset: 1,058,195.99\n",
      "[Validation] Step 4 | Reward: 6.52 | Asset: 1,065,245.39\n",
      "[Validation] Step 5 | Reward: 8.01 | Asset: 1,080,053.78\n",
      "[Validation] Step 56 | Reward: 79.39 | Asset: 1,793,906.90\n",
      "[Validation] Step 57 | Reward: 81.42 | Asset: 1,814,163.23\n",
      "[Validation] Step 58 | Reward: 74.24 | Asset: 1,742,424.89\n",
      "[Validation] Step 59 | Reward: 78.87 | Asset: 1,788,658.91\n",
      "[Validation] Step 60 | Reward: 78.87 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1793906.9025730002), np.float64(1814163.2325730002), np.float64(1742424.8925730002), np.float64(1788658.912573), 1000000.0]\n",
      "[DEBUG] total reward: 78.86589207872748\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 2 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 3 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 4 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 5 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 56 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 57 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 58 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 59 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 60 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1000000.0), np.float64(1000000.0), np.float64(1000000.0), np.float64(1000000.0), 1000000.0]\n",
      "[DEBUG] total reward: 0.0\n",
      "[EVAL] Sharpe Debug: No volatility or insufficient data.\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: -4.39 | Asset: 956,075.25\n",
      "[TRADE] Step 2 | Reward: -3.26 | Asset: 967,368.09\n",
      "[TRADE] Step 3 | Reward: -4.75 | Asset: 952,462.29\n",
      "[TRADE] Step 4 | Reward: -5.89 | Asset: 941,121.09\n",
      "[TRADE] Step 5 | Reward: -1.87 | Asset: 981,273.41\n",
      "[TRADE] Step 57 | Reward: 84.75 | Asset: 1,847,466.01\n",
      "[TRADE] Step 58 | Reward: 95.94 | Asset: 1,959,402.77\n",
      "[TRADE] Step 59 | Reward: 92.39 | Asset: 1,923,927.85\n",
      "[TRADE] Step 60 | Reward: 99.43 | Asset: 1,994,314.01\n",
      "[TRADE] Step 61 | Reward: 99.43 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(1847466.01212), np.float64(1959402.7721200003), np.float64(1923927.8521200004), np.float64(1994314.01212), 1000000.0]\n",
      "[DEBUG] total reward: 99.43140469491482\n",
      "✅ Best model: A2C with Sharpe 0.5952\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                   NaN\n",
      "1970-01-01 00:00:00.000000001+00:00    0.011812\n",
      "1970-01-01 00:00:00.000000002+00:00   -0.015409\n",
      "1970-01-01 00:00:00.000000003+00:00   -0.011907\n",
      "1970-01-01 00:00:00.000000004+00:00    0.042664\n",
      "                                         ...   \n",
      "1970-01-01 00:00:00.000000056+00:00    0.057754\n",
      "1970-01-01 00:00:00.000000057+00:00    0.060589\n",
      "1970-01-01 00:00:00.000000058+00:00   -0.018105\n",
      "1970-01-01 00:00:00.000000059+00:00    0.036585\n",
      "1970-01-01 00:00:00.000000060+00:00   -0.498574\n",
      "Name: daily_return, Length: 61, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: 0.00505\n",
      "   Std return : 0.08041\n",
      "   Sharpe     : 0.99657\n",
      " Rolling window_3: 2020-07-06 to 2021-05-06\n",
      " Window 3\n",
      "  Train window: 2020-07-06 to 2021-01-06 — 184 days\n",
      "  Val window  : 2021-01-07 to 2021-03-06   — 58 days\n",
      "  Trade window: 2021-03-07 to 2021-05-06 — 60 days\n",
      "count    57.000000\n",
      "mean      0.005109\n",
      "std       0.053418\n",
      "min      -0.132558\n",
      "25%      -0.021228\n",
      "50%      -0.002387\n",
      "75%       0.028103\n",
      "max       0.190998\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1395 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1262         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043327366 |\n",
      "|    clip_fraction        | 0.0364       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0018593669 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.6         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 145          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1197          |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 5             |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.004290629   |\n",
      "|    clip_fraction        | 0.0133        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | -0.0077837706 |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 76.6          |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00166      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 210           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1186          |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 6             |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0055160504  |\n",
      "|    clip_fraction        | 0.0444        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.85         |\n",
      "|    explained_variance   | -0.0005970001 |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 80.2          |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00674      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 209           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1179         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005496374  |\n",
      "|    clip_fraction        | 0.0509       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.0003669262 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.4         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 173          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1132         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046910616 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 8.225441e-05 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 106          |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00472     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 208          |\n",
      "------------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 2.86 | Asset: 1,028,575.98\n",
      "[Validation] Step 2 | Reward: 1.69 | Asset: 1,016,861.00\n",
      "[Validation] Step 3 | Reward: -3.17 | Asset: 968,328.71\n",
      "[Validation] Step 4 | Reward: -3.18 | Asset: 968,232.89\n",
      "[Validation] Step 5 | Reward: -4.92 | Asset: 950,844.00\n",
      "[Validation] Step 54 | Reward: 16.83 | Asset: 1,168,301.31\n",
      "[Validation] Step 55 | Reward: 16.83 | Asset: 1,168,273.93\n",
      "[Validation] Step 56 | Reward: 12.27 | Asset: 1,122,726.68\n",
      "[Validation] Step 57 | Reward: 13.13 | Asset: 1,131,345.50\n",
      "[Validation] Step 58 | Reward: 13.13 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 58\n",
      "[DEBUG] Last 5 values: [np.float64(1168301.3083307692), np.float64(1168273.9276522181), np.float64(1122726.684101218), np.float64(1131345.5005632183), 1000000.0]\n",
      "[DEBUG] total reward: 13.134552137926221\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 2.86 | Asset: 1,028,575.98\n",
      "[Validation] Step 2 | Reward: 1.69 | Asset: 1,016,861.00\n",
      "[Validation] Step 3 | Reward: -3.18 | Asset: 968,166.75\n",
      "[Validation] Step 4 | Reward: -5.05 | Asset: 949,495.19\n",
      "[Validation] Step 5 | Reward: -8.63 | Asset: 913,718.66\n",
      "[Validation] Step 54 | Reward: 18.62 | Asset: 1,186,205.62\n",
      "[Validation] Step 55 | Reward: 23.98 | Asset: 1,239,837.61\n",
      "[Validation] Step 56 | Reward: 20.14 | Asset: 1,201,414.27\n",
      "[Validation] Step 57 | Reward: 20.37 | Asset: 1,203,704.29\n",
      "[Validation] Step 58 | Reward: 20.37 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 58\n",
      "[DEBUG] Last 5 values: [np.float64(1186205.6244458158), np.float64(1239837.6144458158), np.float64(1201414.2744458157), np.float64(1203704.2944458157), 1000000.0]\n",
      "[DEBUG] total reward: 20.370430821552873\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 2.86 | Asset: 1,028,575.98\n",
      "[Validation] Step 2 | Reward: 1.69 | Asset: 1,016,861.00\n",
      "[Validation] Step 3 | Reward: -3.18 | Asset: 968,166.75\n",
      "[Validation] Step 4 | Reward: -10.23 | Asset: 897,688.36\n",
      "[Validation] Step 5 | Reward: -13.65 | Asset: 863,452.26\n",
      "[Validation] Step 54 | Reward: 22.80 | Asset: 1,227,990.33\n",
      "[Validation] Step 55 | Reward: 27.66 | Asset: 1,276,598.34\n",
      "[Validation] Step 56 | Reward: 22.69 | Asset: 1,226,903.28\n",
      "[Validation] Step 57 | Reward: 23.62 | Asset: 1,236,223.66\n",
      "[Validation] Step 58 | Reward: 23.62 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 58\n",
      "[DEBUG] Last 5 values: [np.float64(1227990.3319430002), np.float64(1276598.3419430002), np.float64(1226903.2819430002), np.float64(1236223.661943), 1000000.0]\n",
      "[DEBUG] total reward: 23.622365452349186\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: 2.85 | Asset: 1,028,491.39\n",
      "[TRADE] Step 2 | Reward: 7.68 | Asset: 1,076,840.60\n",
      "[TRADE] Step 3 | Reward: 9.39 | Asset: 1,093,858.29\n",
      "[TRADE] Step 4 | Reward: 13.09 | Asset: 1,130,920.00\n",
      "[TRADE] Step 5 | Reward: 11.94 | Asset: 1,119,368.40\n",
      "[TRADE] Step 56 | Reward: 12.84 | Asset: 1,128,443.99\n",
      "[TRADE] Step 57 | Reward: 14.83 | Asset: 1,148,343.05\n",
      "[TRADE] Step 58 | Reward: 6.95 | Asset: 1,069,468.29\n",
      "[TRADE] Step 59 | Reward: 15.51 | Asset: 1,155,088.69\n",
      "[TRADE] Step 60 | Reward: 15.51 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1128443.986587), np.float64(1148343.046587), np.float64(1069468.2865870001), np.float64(1155088.686587), 1000000.0]\n",
      "[DEBUG] total reward: 15.508869260549545\n",
      "✅ Best model: DDPG with Sharpe 0.3344\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                   NaN\n",
      "1970-01-01 00:00:00.000000001+00:00    0.047010\n",
      "1970-01-01 00:00:00.000000002+00:00    0.015803\n",
      "1970-01-01 00:00:00.000000003+00:00    0.033882\n",
      "1970-01-01 00:00:00.000000004+00:00   -0.010214\n",
      "1970-01-01 00:00:00.000000005+00:00    0.069842\n",
      "1970-01-01 00:00:00.000000006+00:00   -0.036339\n",
      "1970-01-01 00:00:00.000000007+00:00   -0.056222\n",
      "1970-01-01 00:00:00.000000008+00:00    0.022793\n",
      "1970-01-01 00:00:00.000000009+00:00    0.034619\n",
      "1970-01-01 00:00:00.000000010+00:00   -0.021593\n",
      "1970-01-01 00:00:00.000000011+00:00    0.006961\n",
      "1970-01-01 00:00:00.000000012+00:00    0.001162\n",
      "1970-01-01 00:00:00.000000013+00:00   -0.012913\n",
      "1970-01-01 00:00:00.000000014+00:00   -0.056975\n",
      "1970-01-01 00:00:00.000000015+00:00    0.004407\n",
      "1970-01-01 00:00:00.000000016+00:00   -0.037879\n",
      "1970-01-01 00:00:00.000000017+00:00   -0.018695\n",
      "1970-01-01 00:00:00.000000018+00:00    0.072686\n",
      "1970-01-01 00:00:00.000000019+00:00    0.014202\n",
      "1970-01-01 00:00:00.000000020+00:00   -0.001110\n",
      "1970-01-01 00:00:00.000000021+00:00    0.034511\n",
      "1970-01-01 00:00:00.000000022+00:00    0.019091\n",
      "1970-01-01 00:00:00.000000023+00:00    0.001136\n",
      "1970-01-01 00:00:00.000000024+00:00    0.000429\n",
      "1970-01-01 00:00:00.000000025+00:00    0.006377\n",
      "1970-01-01 00:00:00.000000026+00:00   -0.033065\n",
      "1970-01-01 00:00:00.000000027+00:00    0.020580\n",
      "1970-01-01 00:00:00.000000028+00:00    0.015917\n",
      "1970-01-01 00:00:00.000000029+00:00   -0.018550\n",
      "1970-01-01 00:00:00.000000030+00:00   -0.036303\n",
      "1970-01-01 00:00:00.000000031+00:00    0.038644\n",
      "1970-01-01 00:00:00.000000032+00:00    0.000868\n",
      "1970-01-01 00:00:00.000000033+00:00    0.028106\n",
      "1970-01-01 00:00:00.000000034+00:00    0.004048\n",
      "1970-01-01 00:00:00.000000035+00:00   -0.002504\n",
      "1970-01-01 00:00:00.000000036+00:00    0.062483\n",
      "1970-01-01 00:00:00.000000037+00:00   -0.007436\n",
      "1970-01-01 00:00:00.000000038+00:00    0.004252\n",
      "1970-01-01 00:00:00.000000039+00:00   -0.029160\n",
      "1970-01-01 00:00:00.000000040+00:00   -0.022430\n",
      "1970-01-01 00:00:00.000000041+00:00   -0.063230\n",
      "1970-01-01 00:00:00.000000042+00:00   -0.010079\n",
      "1970-01-01 00:00:00.000000043+00:00    0.016497\n",
      "1970-01-01 00:00:00.000000044+00:00   -0.044530\n",
      "1970-01-01 00:00:00.000000045+00:00   -0.036723\n",
      "1970-01-01 00:00:00.000000046+00:00   -0.011018\n",
      "1970-01-01 00:00:00.000000047+00:00   -0.022912\n",
      "1970-01-01 00:00:00.000000048+00:00   -0.016862\n",
      "1970-01-01 00:00:00.000000049+00:00    0.100139\n",
      "1970-01-01 00:00:00.000000050+00:00    0.020154\n",
      "1970-01-01 00:00:00.000000051+00:00   -0.001528\n",
      "1970-01-01 00:00:00.000000052+00:00   -0.022323\n",
      "1970-01-01 00:00:00.000000053+00:00    0.073930\n",
      "1970-01-01 00:00:00.000000054+00:00    0.004464\n",
      "1970-01-01 00:00:00.000000055+00:00   -0.020090\n",
      "1970-01-01 00:00:00.000000056+00:00    0.017634\n",
      "1970-01-01 00:00:00.000000057+00:00   -0.068686\n",
      "1970-01-01 00:00:00.000000058+00:00    0.080059\n",
      "1970-01-01 00:00:00.000000059+00:00   -0.134266\n",
      "Name: daily_return, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: 0.00032\n",
      "   Std return : 0.04017\n",
      "   Sharpe     : 0.12762\n",
      " Rolling window_4: 2020-10-06 to 2021-08-06\n",
      " Window 4\n",
      "  Train window: 2020-10-06 to 2021-04-06 — 182 days\n",
      "  Val window  : 2021-04-07 to 2021-06-06   — 60 days\n",
      "  Trade window: 2021-06-07 to 2021-08-06 — 60 days\n",
      "count    59.000000\n",
      "mean     -0.005745\n",
      "std       0.051352\n",
      "min      -0.153507\n",
      "25%      -0.030241\n",
      "50%      -0.007857\n",
      "75%       0.019167\n",
      "max       0.127697\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1416 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1259          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0053647216  |\n",
      "|    clip_fraction        | 0.0397        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | -0.0004067421 |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 300           |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00413      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 624           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1223         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055563697 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.001604557 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 255          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 514          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1179          |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 6             |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.006428728   |\n",
      "|    clip_fraction        | 0.0443        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.00013649464 |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 216           |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00446      |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 560           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1175         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044407193 |\n",
      "|    clip_fraction        | 0.0298       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0002412796 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 505          |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 869          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1170         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004683518  |\n",
      "|    clip_fraction        | 0.0463       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 9.691715e-05 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 249          |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00431     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 553          |\n",
      "------------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 3.60 | Asset: 1,036,014.07\n",
      "[Validation] Step 2 | Reward: 3.68 | Asset: 1,036,802.05\n",
      "[Validation] Step 3 | Reward: 6.44 | Asset: 1,064,449.33\n",
      "[Validation] Step 4 | Reward: 6.88 | Asset: 1,068,803.88\n",
      "[Validation] Step 5 | Reward: 6.64 | Asset: 1,066,377.83\n",
      "[Validation] Step 56 | Reward: -3.64 | Asset: 963,648.02\n",
      "[Validation] Step 57 | Reward: -2.14 | Asset: 978,630.04\n",
      "[Validation] Step 58 | Reward: -4.25 | Asset: 957,469.75\n",
      "[Validation] Step 59 | Reward: -7.21 | Asset: 927,946.78\n",
      "[Validation] Step 60 | Reward: -7.21 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(963648.0232760396), np.float64(978630.0393760398), np.float64(957469.7500152017), np.float64(927946.7753641662), 1000000.0]\n",
      "[DEBUG] total reward: -7.2053212752252875\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 3.60 | Asset: 1,036,014.07\n",
      "[Validation] Step 2 | Reward: 3.71 | Asset: 1,037,119.41\n",
      "[Validation] Step 3 | Reward: 6.48 | Asset: 1,064,771.44\n",
      "[Validation] Step 4 | Reward: 6.89 | Asset: 1,068,917.67\n",
      "[Validation] Step 5 | Reward: 6.65 | Asset: 1,066,494.17\n",
      "[Validation] Step 56 | Reward: -32.11 | Asset: 678,856.32\n",
      "[Validation] Step 57 | Reward: -29.09 | Asset: 709,062.30\n",
      "[Validation] Step 58 | Reward: -33.45 | Asset: 665,542.08\n",
      "[Validation] Step 59 | Reward: -35.81 | Asset: 641,857.68\n",
      "[Validation] Step 60 | Reward: -35.81 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(678856.3235311665), np.float64(709062.3035311665), np.float64(665542.0835311665), np.float64(641857.6835311665), 1000000.0]\n",
      "[DEBUG] total reward: -35.814231999218464\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 1.17 | Asset: 1,011,679.37\n",
      "[Validation] Step 2 | Reward: 0.89 | Asset: 1,008,940.56\n",
      "[Validation] Step 3 | Reward: 2.89 | Asset: 1,028,905.89\n",
      "[Validation] Step 4 | Reward: 3.60 | Asset: 1,036,032.56\n",
      "[Validation] Step 5 | Reward: 2.94 | Asset: 1,029,439.86\n",
      "[Validation] Step 56 | Reward: 30.29 | Asset: 1,302,902.79\n",
      "[Validation] Step 57 | Reward: 37.55 | Asset: 1,375,548.22\n",
      "[Validation] Step 58 | Reward: 29.49 | Asset: 1,294,865.28\n",
      "[Validation] Step 59 | Reward: 26.51 | Asset: 1,265,149.10\n",
      "[Validation] Step 60 | Reward: 26.51 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1302902.7910839997), np.float64(1375548.2210839998), np.float64(1294865.281084), np.float64(1265149.101084), 1000000.0]\n",
      "[DEBUG] total reward: 26.5149072855711\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: -0.85 | Asset: 991,492.08\n",
      "[TRADE] Step 2 | Reward: 1.21 | Asset: 1,012,057.01\n",
      "[TRADE] Step 3 | Reward: -2.97 | Asset: 970,303.91\n",
      "[TRADE] Step 4 | Reward: -7.56 | Asset: 924,385.81\n",
      "[TRADE] Step 5 | Reward: -6.91 | Asset: 930,943.97\n",
      "[TRADE] Step 56 | Reward: 2.35 | Asset: 1,023,530.45\n",
      "[TRADE] Step 57 | Reward: -1.48 | Asset: 985,157.57\n",
      "[TRADE] Step 58 | Reward: 6.97 | Asset: 1,069,727.65\n",
      "[TRADE] Step 59 | Reward: 10.98 | Asset: 1,109,793.97\n",
      "[TRADE] Step 60 | Reward: 10.98 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1023530.4513719999), np.float64(985157.5713719999), np.float64(1069727.651372), np.float64(1109793.971372), 1000000.0]\n",
      "[DEBUG] total reward: 10.979397628456354\n",
      "✅ Best model: DDPG with Sharpe 0.6494\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                   NaN\n",
      "1970-01-01 00:00:00.000000001+00:00    0.020741\n",
      "1970-01-01 00:00:00.000000002+00:00   -0.041256\n",
      "1970-01-01 00:00:00.000000003+00:00   -0.047323\n",
      "1970-01-01 00:00:00.000000004+00:00    0.007095\n",
      "1970-01-01 00:00:00.000000005+00:00    0.058357\n",
      "1970-01-01 00:00:00.000000006+00:00    0.028423\n",
      "1970-01-01 00:00:00.000000007+00:00   -0.014403\n",
      "1970-01-01 00:00:00.000000008+00:00   -0.068946\n",
      "1970-01-01 00:00:00.000000009+00:00    0.002272\n",
      "1970-01-01 00:00:00.000000010+00:00   -0.058547\n",
      "1970-01-01 00:00:00.000000011+00:00   -0.031016\n",
      "1970-01-01 00:00:00.000000012+00:00    0.036334\n",
      "1970-01-01 00:00:00.000000013+00:00   -0.159273\n",
      "1970-01-01 00:00:00.000000014+00:00   -0.003286\n",
      "1970-01-01 00:00:00.000000015+00:00    0.047181\n",
      "1970-01-01 00:00:00.000000016+00:00    0.010840\n",
      "1970-01-01 00:00:00.000000017+00:00   -0.090638\n",
      "1970-01-01 00:00:00.000000018+00:00    0.011484\n",
      "1970-01-01 00:00:00.000000019+00:00    0.083239\n",
      "1970-01-01 00:00:00.000000020+00:00    0.051415\n",
      "1970-01-01 00:00:00.000000021+00:00    0.038745\n",
      "1970-01-01 00:00:00.000000022+00:00    0.050865\n",
      "1970-01-01 00:00:00.000000023+00:00   -0.074248\n",
      "1970-01-01 00:00:00.000000024+00:00    0.022610\n",
      "1970-01-01 00:00:00.000000025+00:00    0.033759\n",
      "1970-01-01 00:00:00.000000026+00:00    0.042894\n",
      "1970-01-01 00:00:00.000000027+00:00   -0.054220\n",
      "1970-01-01 00:00:00.000000028+00:00    0.057242\n",
      "1970-01-01 00:00:00.000000029+00:00   -0.002549\n",
      "1970-01-01 00:00:00.000000030+00:00   -0.086285\n",
      "1970-01-01 00:00:00.000000031+00:00    0.014459\n",
      "1970-01-01 00:00:00.000000032+00:00   -0.016875\n",
      "1970-01-01 00:00:00.000000033+00:00    0.014072\n",
      "1970-01-01 00:00:00.000000034+00:00   -0.050765\n",
      "1970-01-01 00:00:00.000000035+00:00   -0.044913\n",
      "1970-01-01 00:00:00.000000036+00:00    0.027995\n",
      "1970-01-01 00:00:00.000000037+00:00   -0.037559\n",
      "1970-01-01 00:00:00.000000038+00:00   -0.022484\n",
      "1970-01-01 00:00:00.000000039+00:00    0.012407\n",
      "1970-01-01 00:00:00.000000040+00:00   -0.004176\n",
      "1970-01-01 00:00:00.000000041+00:00   -0.038460\n",
      "1970-01-01 00:00:00.000000042+00:00   -0.017939\n",
      "1970-01-01 00:00:00.000000043+00:00    0.117013\n",
      "1970-01-01 00:00:00.000000044+00:00    0.014533\n",
      "1970-01-01 00:00:00.000000045+00:00    0.049140\n",
      "1970-01-01 00:00:00.000000046+00:00    0.028426\n",
      "1970-01-01 00:00:00.000000047+00:00    0.002303\n",
      "1970-01-01 00:00:00.000000048+00:00    0.017453\n",
      "1970-01-01 00:00:00.000000049+00:00    0.031991\n",
      "1970-01-01 00:00:00.000000050+00:00    0.000612\n",
      "1970-01-01 00:00:00.000000051+00:00    0.035583\n",
      "1970-01-01 00:00:00.000000052+00:00    0.033049\n",
      "1970-01-01 00:00:00.000000053+00:00    0.028079\n",
      "1970-01-01 00:00:00.000000054+00:00    0.009719\n",
      "1970-01-01 00:00:00.000000055+00:00    0.020017\n",
      "1970-01-01 00:00:00.000000056+00:00   -0.037491\n",
      "1970-01-01 00:00:00.000000057+00:00    0.085844\n",
      "1970-01-01 00:00:00.000000058+00:00    0.037455\n",
      "1970-01-01 00:00:00.000000059+00:00   -0.098932\n",
      "Name: daily_return, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: 0.00139\n",
      "   Std return : 0.04976\n",
      "   Sharpe     : 0.44370\n",
      " Rolling window_5: 2021-01-06 to 2021-11-06\n",
      " Window 5\n",
      "  Train window: 2021-01-06 to 2021-07-06 — 181 days\n",
      "  Val window  : 2021-07-07 to 2021-09-06   — 61 days\n",
      "  Trade window: 2021-09-07 to 2021-11-06 — 60 days\n",
      "count    60.000000\n",
      "mean      0.007707\n",
      "std       0.031710\n",
      "min      -0.043355\n",
      "25%      -0.015589\n",
      "50%       0.004485\n",
      "75%       0.032069\n",
      "max       0.081188\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1313 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1080         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041472707 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0031632185 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 91.1         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 167          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1094        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004418074 |\n",
      "|    clip_fraction        | 0.0356      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.004810095 |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.7        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1105        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003819454 |\n",
      "|    clip_fraction        | 0.0224      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.007026911 |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94          |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 190         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1110        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003589482 |\n",
      "|    clip_fraction        | 0.0263      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.014000714 |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.4        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00155    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1107         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035505581 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.01918894   |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 118          |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 250          |\n",
      "------------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -2.00 | Asset: 979,952.83\n",
      "[Validation] Step 2 | Reward: -1.51 | Asset: 984,889.13\n",
      "[Validation] Step 3 | Reward: -2.33 | Asset: 976,693.54\n",
      "[Validation] Step 4 | Reward: -0.47 | Asset: 995,320.16\n",
      "[Validation] Step 5 | Reward: -4.49 | Asset: 955,077.36\n",
      "[Validation] Step 57 | Reward: 55.72 | Asset: 1,557,249.57\n",
      "[Validation] Step 58 | Reward: 58.05 | Asset: 1,580,513.39\n",
      "[Validation] Step 59 | Reward: 57.94 | Asset: 1,579,382.39\n",
      "[Validation] Step 60 | Reward: 63.63 | Asset: 1,636,298.93\n",
      "[Validation] Step 61 | Reward: 63.63 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(1557249.5711848014), np.float64(1580513.3885967627), np.float64(1579382.3890006752), np.float64(1636298.9307089727), 1000000.0]\n",
      "[DEBUG] total reward: 63.62989294389263\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -3.01 | Asset: 969,892.61\n",
      "[Validation] Step 2 | Reward: -3.02 | Asset: 969,795.79\n",
      "[Validation] Step 3 | Reward: -3.91 | Asset: 960,938.78\n",
      "[Validation] Step 4 | Reward: -3.62 | Asset: 963,799.87\n",
      "[Validation] Step 5 | Reward: -7.21 | Asset: 927,943.33\n",
      "[Validation] Step 57 | Reward: 33.55 | Asset: 1,335,510.88\n",
      "[Validation] Step 58 | Reward: 38.92 | Asset: 1,389,172.41\n",
      "[Validation] Step 59 | Reward: 37.06 | Asset: 1,370,641.58\n",
      "[Validation] Step 60 | Reward: 39.35 | Asset: 1,393,464.21\n",
      "[Validation] Step 61 | Reward: 39.35 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(1335510.8818430104), np.float64(1389172.4134609571), np.float64(1370641.5844650425), np.float64(1393464.2084252133), 1000000.0]\n",
      "[DEBUG] total reward: 39.346419947221875\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 2 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 3 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 4 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 5 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 57 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 58 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 59 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 60 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 61 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(1000000.0), np.float64(1000000.0), np.float64(1000000.0), np.float64(1000000.0), 1000000.0]\n",
      "[DEBUG] total reward: 0.0\n",
      "[EVAL] Sharpe Debug: No volatility or insufficient data.\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[TRADE] Step 2 | Reward: 0.58 | Asset: 1,005,802.70\n",
      "[TRADE] Step 3 | Reward: -2.85 | Asset: 971,475.85\n",
      "[TRADE] Step 4 | Reward: -2.12 | Asset: 978,765.11\n",
      "[TRADE] Step 5 | Reward: -2.13 | Asset: 978,667.51\n",
      "[TRADE] Step 56 | Reward: 21.95 | Asset: 1,219,503.73\n",
      "[TRADE] Step 57 | Reward: 22.23 | Asset: 1,222,314.23\n",
      "[TRADE] Step 58 | Reward: 20.35 | Asset: 1,203,491.03\n",
      "[TRADE] Step 59 | Reward: 18.81 | Asset: 1,188,119.94\n",
      "[TRADE] Step 60 | Reward: 18.81 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1219503.7345888366), np.float64(1222314.2349326022), np.float64(1203491.0259630186), np.float64(1188119.9402374632), 1000000.0]\n",
      "[DEBUG] total reward: 18.811994269199204\n",
      "✅ Best model: PPO with Sharpe 0.6760\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                   NaN\n",
      "1970-01-01 00:00:00.000000001+00:00    0.005803\n",
      "1970-01-01 00:00:00.000000002+00:00   -0.034129\n",
      "1970-01-01 00:00:00.000000003+00:00    0.007503\n",
      "1970-01-01 00:00:00.000000004+00:00   -0.000100\n",
      "1970-01-01 00:00:00.000000005+00:00   -0.001413\n",
      "1970-01-01 00:00:00.000000006+00:00    0.009849\n",
      "1970-01-01 00:00:00.000000007+00:00    0.023701\n",
      "1970-01-01 00:00:00.000000008+00:00   -0.008625\n",
      "1970-01-01 00:00:00.000000009+00:00   -0.008767\n",
      "1970-01-01 00:00:00.000000010+00:00    0.019999\n",
      "1970-01-01 00:00:00.000000011+00:00   -0.022135\n",
      "1970-01-01 00:00:00.000000012+00:00   -0.085360\n",
      "1970-01-01 00:00:00.000000013+00:00   -0.052898\n",
      "1970-01-01 00:00:00.000000014+00:00    0.068773\n",
      "1970-01-01 00:00:00.000000015+00:00    0.029852\n",
      "1970-01-01 00:00:00.000000016+00:00   -0.043468\n",
      "1970-01-01 00:00:00.000000017+00:00   -0.000955\n",
      "1970-01-01 00:00:00.000000018+00:00    0.015619\n",
      "1970-01-01 00:00:00.000000019+00:00   -0.023711\n",
      "1970-01-01 00:00:00.000000020+00:00   -0.000100\n",
      "1970-01-01 00:00:00.000000021+00:00    0.012145\n",
      "1970-01-01 00:00:00.000000022+00:00    0.003590\n",
      "1970-01-01 00:00:00.000000023+00:00    0.033247\n",
      "1970-01-01 00:00:00.000000024+00:00    0.002475\n",
      "1970-01-01 00:00:00.000000025+00:00    0.010744\n",
      "1970-01-01 00:00:00.000000026+00:00    0.012435\n",
      "1970-01-01 00:00:00.000000027+00:00    0.043393\n",
      "1970-01-01 00:00:00.000000028+00:00    0.001886\n",
      "1970-01-01 00:00:00.000000029+00:00   -0.027460\n",
      "1970-01-01 00:00:00.000000030+00:00    0.000998\n",
      "1970-01-01 00:00:00.000000031+00:00    0.000544\n",
      "1970-01-01 00:00:00.000000032+00:00   -0.000004\n",
      "1970-01-01 00:00:00.000000033+00:00    0.002740\n",
      "1970-01-01 00:00:00.000000034+00:00   -0.005209\n",
      "1970-01-01 00:00:00.000000035+00:00    0.019839\n",
      "1970-01-01 00:00:00.000000036+00:00    0.036985\n",
      "1970-01-01 00:00:00.000000037+00:00    0.032732\n",
      "1970-01-01 00:00:00.000000038+00:00   -0.006697\n",
      "1970-01-01 00:00:00.000000039+00:00    0.004365\n",
      "1970-01-01 00:00:00.000000040+00:00   -0.026420\n",
      "1970-01-01 00:00:00.000000041+00:00    0.022412\n",
      "1970-01-01 00:00:00.000000042+00:00    0.055201\n",
      "1970-01-01 00:00:00.000000043+00:00   -0.025932\n",
      "1970-01-01 00:00:00.000000044+00:00   -0.019868\n",
      "1970-01-01 00:00:00.000000045+00:00    0.036852\n",
      "1970-01-01 00:00:00.000000046+00:00   -0.017369\n",
      "1970-01-01 00:00:00.000000047+00:00    0.034318\n",
      "1970-01-01 00:00:00.000000048+00:00   -0.025066\n",
      "1970-01-01 00:00:00.000000049+00:00   -0.050590\n",
      "1970-01-01 00:00:00.000000050+00:00    0.092490\n",
      "1970-01-01 00:00:00.000000051+00:00    0.030902\n",
      "1970-01-01 00:00:00.000000052+00:00   -0.021705\n",
      "1970-01-01 00:00:00.000000053+00:00   -0.008180\n",
      "1970-01-01 00:00:00.000000054+00:00    0.007491\n",
      "1970-01-01 00:00:00.000000055+00:00    0.062416\n",
      "1970-01-01 00:00:00.000000056+00:00    0.002305\n",
      "1970-01-01 00:00:00.000000057+00:00   -0.015400\n",
      "1970-01-01 00:00:00.000000058+00:00   -0.012772\n",
      "1970-01-01 00:00:00.000000059+00:00   -0.158334\n",
      "Name: daily_return, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: 0.00069\n",
      "   Std return : 0.03697\n",
      "   Sharpe     : 0.29797\n",
      " Rolling window_6: 2021-04-06 to 2022-02-06\n",
      " Window 6\n",
      "  Train window: 2021-04-06 to 2021-10-06 — 183 days\n",
      "  Val window  : 2021-10-07 to 2021-12-06   — 60 days\n",
      "  Trade window: 2021-12-07 to 2022-02-06 — 61 days\n",
      "count    59.000000\n",
      "mean     -0.000607\n",
      "std       0.033209\n",
      "min      -0.090060\n",
      "25%      -0.016041\n",
      "50%       0.002473\n",
      "75%       0.024467\n",
      "max       0.072011\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1385 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1122         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047958056 |\n",
      "|    clip_fraction        | 0.0417       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.010017157 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.9         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 83.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1054         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047085835 |\n",
      "|    clip_fraction        | 0.0461       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | -0.00254488  |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.7         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 98.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1020          |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00257545    |\n",
      "|    clip_fraction        | 0.014         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.85         |\n",
      "|    explained_variance   | -0.0024747849 |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 60.2          |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00117      |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 104           |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1037           |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 9              |\n",
      "|    total_timesteps      | 10240          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0048695887   |\n",
      "|    clip_fraction        | 0.0518         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.85          |\n",
      "|    explained_variance   | -0.00012075901 |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 39.9           |\n",
      "|    n_updates            | 40             |\n",
      "|    policy_gradient_loss | -0.00497       |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 86.5           |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1054         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028503016 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.0021086931 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.4         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 0.27 | Asset: 1,002,697.38\n",
      "[Validation] Step 2 | Reward: 2.08 | Asset: 1,020,760.12\n",
      "[Validation] Step 3 | Reward: 1.42 | Asset: 1,014,242.36\n",
      "[Validation] Step 4 | Reward: 6.49 | Asset: 1,064,861.93\n",
      "[Validation] Step 5 | Reward: 3.83 | Asset: 1,038,322.37\n",
      "[Validation] Step 56 | Reward: 16.04 | Asset: 1,160,355.29\n",
      "[Validation] Step 57 | Reward: 10.10 | Asset: 1,100,993.90\n",
      "[Validation] Step 58 | Reward: 1.20 | Asset: 1,012,019.77\n",
      "[Validation] Step 59 | Reward: 1.74 | Asset: 1,017,448.42\n",
      "[Validation] Step 60 | Reward: 1.74 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1160355.289463794), np.float64(1100993.9027377942), np.float64(1012019.7732997943), np.float64(1017448.4212247944), 1000000.0]\n",
      "[DEBUG] total reward: 1.7448422515299171\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 0.27 | Asset: 1,002,697.38\n",
      "[Validation] Step 2 | Reward: 0.38 | Asset: 1,003,827.15\n",
      "[Validation] Step 3 | Reward: -2.06 | Asset: 979,374.01\n",
      "[Validation] Step 4 | Reward: 1.16 | Asset: 1,011,591.50\n",
      "[Validation] Step 5 | Reward: -0.29 | Asset: 997,133.46\n",
      "[Validation] Step 56 | Reward: 28.79 | Asset: 1,287,928.30\n",
      "[Validation] Step 57 | Reward: 20.37 | Asset: 1,203,668.38\n",
      "[Validation] Step 58 | Reward: 17.56 | Asset: 1,175,585.54\n",
      "[Validation] Step 59 | Reward: 19.82 | Asset: 1,198,167.58\n",
      "[Validation] Step 60 | Reward: 19.82 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1287928.3032739714), np.float64(1203668.3755081634), np.float64(1175585.5350912933), np.float64(1198167.5835540465), 1000000.0]\n",
      "[DEBUG] total reward: 19.816759333014488\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -0.25 | Asset: 997,530.13\n",
      "[Validation] Step 2 | Reward: -0.02 | Asset: 999,832.49\n",
      "[Validation] Step 3 | Reward: -4.50 | Asset: 954,996.85\n",
      "[Validation] Step 4 | Reward: -0.93 | Asset: 990,680.95\n",
      "[Validation] Step 5 | Reward: -2.35 | Asset: 976,546.81\n",
      "[Validation] Step 56 | Reward: 26.11 | Asset: 1,261,057.06\n",
      "[Validation] Step 57 | Reward: 17.86 | Asset: 1,178,618.14\n",
      "[Validation] Step 58 | Reward: 15.11 | Asset: 1,151,142.22\n",
      "[Validation] Step 59 | Reward: 17.32 | Asset: 1,173,236.23\n",
      "[Validation] Step 60 | Reward: 17.32 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1261057.062922), np.float64(1178618.1429219998), np.float64(1151142.2229219999), np.float64(1173236.2329219996), 1000000.0]\n",
      "[DEBUG] total reward: 17.32362374663353\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: 1.30 | Asset: 1,013,007.94\n",
      "[TRADE] Step 2 | Reward: -5.33 | Asset: 946,709.57\n",
      "[TRADE] Step 3 | Reward: -10.11 | Asset: 898,926.25\n",
      "[TRADE] Step 4 | Reward: -5.70 | Asset: 942,955.15\n",
      "[TRADE] Step 5 | Reward: -4.77 | Asset: 952,300.05\n",
      "[TRADE] Step 57 | Reward: -38.10 | Asset: 618,954.15\n",
      "[TRADE] Step 58 | Reward: -37.76 | Asset: 622,355.85\n",
      "[TRADE] Step 59 | Reward: -30.88 | Asset: 691,247.75\n",
      "[TRADE] Step 60 | Reward: -30.47 | Asset: 695,309.55\n",
      "[TRADE] Step 61 | Reward: -30.47 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(618954.14998), np.float64(622355.84998), np.float64(691247.74998), np.float64(695309.54998), 1000000.0]\n",
      "[DEBUG] total reward: -30.469045222271234\n",
      "✅ Best model: DDPG with Sharpe 0.3672\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                   NaN\n",
      "1970-01-01 00:00:00.000000001+00:00   -0.065447\n",
      "1970-01-01 00:00:00.000000002+00:00   -0.050473\n",
      "1970-01-01 00:00:00.000000003+00:00    0.048979\n",
      "1970-01-01 00:00:00.000000004+00:00    0.009910\n",
      "                                         ...   \n",
      "1970-01-01 00:00:00.000000056+00:00   -0.038089\n",
      "1970-01-01 00:00:00.000000057+00:00    0.005496\n",
      "1970-01-01 00:00:00.000000058+00:00    0.110695\n",
      "1970-01-01 00:00:00.000000059+00:00    0.005876\n",
      "1970-01-01 00:00:00.000000060+00:00    0.438208\n",
      "Name: daily_return, Length: 61, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: 0.00187\n",
      "   Std return : 0.07009\n",
      "   Sharpe     : 0.42342\n",
      " Rolling window_7: 2021-07-06 to 2022-05-06\n",
      " Window 7\n",
      "  Train window: 2021-07-06 to 2022-01-06 — 184 days\n",
      "  Val window  : 2022-01-07 to 2022-03-06   — 58 days\n",
      "  Trade window: 2022-03-07 to 2022-05-06 — 60 days\n",
      "count    57.000000\n",
      "mean     -0.000378\n",
      "std       0.038381\n",
      "min      -0.106884\n",
      "25%      -0.021699\n",
      "50%       0.000926\n",
      "75%       0.012586\n",
      "max       0.142998\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1381 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1122          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0030127298  |\n",
      "|    clip_fraction        | 0.0131        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | -0.0012807846 |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 53            |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.000606     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 101           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1128         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025117928 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.002911508  |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.9         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00107     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1120         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073867654 |\n",
      "|    clip_fraction        | 0.0478       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.003055632  |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.4         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 88.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1078         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064265234 |\n",
      "|    clip_fraction        | 0.0368       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.88        |\n",
      "|    explained_variance   | 0.005198121  |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.8         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 138          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1066         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067413813 |\n",
      "|    clip_fraction        | 0.05         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.88        |\n",
      "|    explained_variance   | 0.009727895  |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.9         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 149          |\n",
      "------------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -0.68 | Asset: 993,229.47\n",
      "[Validation] Step 2 | Reward: 0.13 | Asset: 1,001,282.68\n",
      "[Validation] Step 3 | Reward: -0.40 | Asset: 995,972.66\n",
      "[Validation] Step 4 | Reward: -0.41 | Asset: 995,873.13\n",
      "[Validation] Step 5 | Reward: 0.15 | Asset: 1,001,464.49\n",
      "[Validation] Step 54 | Reward: -8.19 | Asset: 918,069.86\n",
      "[Validation] Step 55 | Reward: -11.37 | Asset: 886,304.00\n",
      "[Validation] Step 56 | Reward: -11.92 | Asset: 880,762.25\n",
      "[Validation] Step 57 | Reward: -11.92 | Asset: 880,755.76\n",
      "[Validation] Step 58 | Reward: -11.92 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 58\n",
      "[DEBUG] Last 5 values: [np.float64(918069.8644805911), np.float64(886304.0008796972), np.float64(880762.2501625328), np.float64(880755.7604086444), 1000000.0]\n",
      "[DEBUG] total reward: -11.924424104392529\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 0.26 | Asset: 1,002,618.48\n",
      "[Validation] Step 2 | Reward: 0.71 | Asset: 1,007,055.60\n",
      "[Validation] Step 3 | Reward: 0.60 | Asset: 1,006,044.48\n",
      "[Validation] Step 4 | Reward: 2.78 | Asset: 1,027,807.68\n",
      "[Validation] Step 5 | Reward: 5.60 | Asset: 1,055,968.56\n",
      "[Validation] Step 54 | Reward: 1.28 | Asset: 1,012,832.25\n",
      "[Validation] Step 55 | Reward: -2.17 | Asset: 978,291.54\n",
      "[Validation] Step 56 | Reward: -9.72 | Asset: 902,789.74\n",
      "[Validation] Step 57 | Reward: -8.95 | Asset: 910,499.23\n",
      "[Validation] Step 58 | Reward: -8.95 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 58\n",
      "[DEBUG] Last 5 values: [np.float64(1012832.248203513), np.float64(978291.5410852429), np.float64(902789.7401187514), np.float64(910499.2279304084), 1000000.0]\n",
      "[DEBUG] total reward: -8.950077616609633\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -1.19 | Asset: 988,139.01\n",
      "[Validation] Step 2 | Reward: 0.23 | Asset: 1,002,312.20\n",
      "[Validation] Step 3 | Reward: -1.85 | Asset: 981,493.68\n",
      "[Validation] Step 4 | Reward: 3.14 | Asset: 1,031,426.85\n",
      "[Validation] Step 5 | Reward: 7.33 | Asset: 1,073,256.57\n",
      "[Validation] Step 54 | Reward: -6.16 | Asset: 938,437.29\n",
      "[Validation] Step 55 | Reward: -9.76 | Asset: 902,404.71\n",
      "[Validation] Step 56 | Reward: -16.50 | Asset: 835,023.69\n",
      "[Validation] Step 57 | Reward: -15.13 | Asset: 848,713.59\n",
      "[Validation] Step 58 | Reward: -15.13 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 58\n",
      "[DEBUG] Last 5 values: [np.float64(938437.2895760001), np.float64(902404.709576), np.float64(835023.689576), np.float64(848713.5895760001), 1000000.0]\n",
      "[DEBUG] total reward: -15.128640107810497\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: 0.85 | Asset: 1,008,460.09\n",
      "[TRADE] Step 2 | Reward: 3.86 | Asset: 1,038,636.33\n",
      "[TRADE] Step 3 | Reward: 0.25 | Asset: 1,002,525.06\n",
      "[TRADE] Step 4 | Reward: -1.66 | Asset: 983,364.60\n",
      "[TRADE] Step 5 | Reward: -1.21 | Asset: 987,949.56\n",
      "[TRADE] Step 56 | Reward: 9.84 | Asset: 1,098,441.72\n",
      "[TRADE] Step 57 | Reward: 6.97 | Asset: 1,069,703.16\n",
      "[TRADE] Step 58 | Reward: 13.07 | Asset: 1,130,736.12\n",
      "[TRADE] Step 59 | Reward: 5.68 | Asset: 1,056,750.84\n",
      "[TRADE] Step 60 | Reward: 5.68 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1098441.72302), np.float64(1069703.1630199999), np.float64(1130736.12302), np.float64(1056750.84302), 1000000.0]\n",
      "[DEBUG] total reward: 5.675083719193935\n",
      "✅ Best model: DDPG with Sharpe 0.4574\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                   NaN\n",
      "1970-01-01 00:00:00.000000001+00:00    0.029923\n",
      "1970-01-01 00:00:00.000000002+00:00   -0.034768\n",
      "1970-01-01 00:00:00.000000003+00:00   -0.019112\n",
      "1970-01-01 00:00:00.000000004+00:00    0.004663\n",
      "1970-01-01 00:00:00.000000005+00:00   -0.020659\n",
      "1970-01-01 00:00:00.000000006+00:00    0.029274\n",
      "1970-01-01 00:00:00.000000007+00:00    0.010920\n",
      "1970-01-01 00:00:00.000000008+00:00    0.059534\n",
      "1970-01-01 00:00:00.000000009+00:00    0.013720\n",
      "1970-01-01 00:00:00.000000010+00:00    0.045101\n",
      "1970-01-01 00:00:00.000000011+00:00    0.004050\n",
      "1970-01-01 00:00:00.000000012+00:00   -0.030276\n",
      "1970-01-01 00:00:00.000000013+00:00    0.009999\n",
      "1970-01-01 00:00:00.000000014+00:00    0.027508\n",
      "1970-01-01 00:00:00.000000015+00:00    0.022316\n",
      "1970-01-01 00:00:00.000000016+00:00    0.024592\n",
      "1970-01-01 00:00:00.000000017+00:00   -0.002767\n",
      "1970-01-01 00:00:00.000000018+00:00    0.013799\n",
      "1970-01-01 00:00:00.000000019+00:00    0.047841\n",
      "1970-01-01 00:00:00.000000020+00:00    0.011295\n",
      "1970-01-01 00:00:00.000000021+00:00    0.020255\n",
      "1970-01-01 00:00:00.000000022+00:00   -0.004324\n",
      "1970-01-01 00:00:00.000000023+00:00   -0.030763\n",
      "1970-01-01 00:00:00.000000024+00:00    0.052869\n",
      "1970-01-01 00:00:00.000000025+00:00   -0.003307\n",
      "1970-01-01 00:00:00.000000026+00:00    0.022664\n",
      "1970-01-01 00:00:00.000000027+00:00   -0.000684\n",
      "1970-01-01 00:00:00.000000028+00:00   -0.031931\n",
      "1970-01-01 00:00:00.000000029+00:00   -0.069915\n",
      "1970-01-01 00:00:00.000000030+00:00    0.018496\n",
      "1970-01-01 00:00:00.000000031+00:00   -0.010770\n",
      "1970-01-01 00:00:00.000000032+00:00    0.020705\n",
      "1970-01-01 00:00:00.000000033+00:00   -0.017020\n",
      "1970-01-01 00:00:00.000000034+00:00   -0.069628\n",
      "1970-01-01 00:00:00.000000035+00:00    0.016060\n",
      "1970-01-01 00:00:00.000000036+00:00    0.029891\n",
      "1970-01-01 00:00:00.000000037+00:00   -0.030843\n",
      "1970-01-01 00:00:00.000000038+00:00    0.006140\n",
      "1970-01-01 00:00:00.000000039+00:00    0.006155\n",
      "1970-01-01 00:00:00.000000040+00:00   -0.023256\n",
      "1970-01-01 00:00:00.000000041+00:00    0.022560\n",
      "1970-01-01 00:00:00.000000042+00:00    0.015104\n",
      "1970-01-01 00:00:00.000000043+00:00   -0.008285\n",
      "1970-01-01 00:00:00.000000044+00:00   -0.030019\n",
      "1970-01-01 00:00:00.000000045+00:00   -0.007093\n",
      "1970-01-01 00:00:00.000000046+00:00   -0.009898\n",
      "1970-01-01 00:00:00.000000047+00:00   -0.004096\n",
      "1970-01-01 00:00:00.000000048+00:00    0.029272\n",
      "1970-01-01 00:00:00.000000049+00:00   -0.065419\n",
      "1970-01-01 00:00:00.000000050+00:00    0.028180\n",
      "1970-01-01 00:00:00.000000051+00:00    0.016582\n",
      "1970-01-01 00:00:00.000000052+00:00   -0.040736\n",
      "1970-01-01 00:00:00.000000053+00:00   -0.032069\n",
      "1970-01-01 00:00:00.000000054+00:00    0.035944\n",
      "1970-01-01 00:00:00.000000055+00:00    0.011217\n",
      "1970-01-01 00:00:00.000000056+00:00   -0.026163\n",
      "1970-01-01 00:00:00.000000057+00:00    0.057056\n",
      "1970-01-01 00:00:00.000000058+00:00   -0.065431\n",
      "1970-01-01 00:00:00.000000059+00:00   -0.053703\n",
      "Name: daily_return, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: 0.00035\n",
      "   Std return : 0.03157\n",
      "   Sharpe     : 0.17686\n",
      " Rolling window_8: 2021-10-06 to 2022-08-06\n",
      " Window 8\n",
      "  Train window: 2021-10-06 to 2022-04-06 — 182 days\n",
      "  Val window  : 2022-04-07 to 2022-06-06   — 60 days\n",
      "  Trade window: 2022-06-07 to 2022-08-06 — 60 days\n",
      "count    59.000000\n",
      "mean     -0.005893\n",
      "std       0.035399\n",
      "min      -0.116342\n",
      "25%      -0.025312\n",
      "50%      -0.003543\n",
      "75%       0.017289\n",
      "max       0.078361\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1397 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1129          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0055373684  |\n",
      "|    clip_fraction        | 0.0332        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | -0.0073652267 |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.4          |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00287      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 40.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1057         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033355139 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.008154452  |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 39.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1027        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006413025 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.008194685 |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 43.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1047         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043593645 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.014040291  |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 46.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1058        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005261705 |\n",
      "|    clip_fraction        | 0.0316      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.01990962  |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 42.4        |\n",
      "-----------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -2.75 | Asset: 972,479.94\n",
      "[Validation] Step 2 | Reward: -2.76 | Asset: 972,382.76\n",
      "[Validation] Step 3 | Reward: -2.76 | Asset: 972,382.76\n",
      "[Validation] Step 4 | Reward: -5.00 | Asset: 950,020.73\n",
      "[Validation] Step 5 | Reward: -5.00 | Asset: 949,990.93\n",
      "[Validation] Step 56 | Reward: -29.58 | Asset: 704,226.09\n",
      "[Validation] Step 57 | Reward: -29.78 | Asset: 702,181.39\n",
      "[Validation] Step 58 | Reward: -29.32 | Asset: 706,841.48\n",
      "[Validation] Step 59 | Reward: -29.32 | Asset: 706,770.90\n",
      "[Validation] Step 60 | Reward: -29.32 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(704226.0893704928), np.float64(702181.3862595132), np.float64(706841.4779405851), np.float64(706770.9005491232), 1000000.0]\n",
      "[DEBUG] total reward: -29.322909343696665\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -2.75 | Asset: 972,479.94\n",
      "[Validation] Step 2 | Reward: -2.76 | Asset: 972,382.76\n",
      "[Validation] Step 3 | Reward: -4.13 | Asset: 958,693.36\n",
      "[Validation] Step 4 | Reward: -5.16 | Asset: 948,396.18\n",
      "[Validation] Step 5 | Reward: -3.83 | Asset: 961,727.62\n",
      "[Validation] Step 56 | Reward: -29.03 | Asset: 709,722.13\n",
      "[Validation] Step 57 | Reward: -30.93 | Asset: 690,738.17\n",
      "[Validation] Step 58 | Reward: -30.92 | Asset: 690,791.45\n",
      "[Validation] Step 59 | Reward: -30.80 | Asset: 691,966.86\n",
      "[Validation] Step 60 | Reward: -30.80 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(709722.1306703073), np.float64(690738.1650883375), np.float64(690791.4453517839), np.float64(691966.8642637234), 1000000.0]\n",
      "[DEBUG] total reward: -30.803312762640417\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 2 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 3 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 4 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 5 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 56 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 57 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 58 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 59 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 60 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1000000.0), np.float64(1000000.0), np.float64(1000000.0), np.float64(1000000.0), 1000000.0]\n",
      "[DEBUG] total reward: 0.0\n",
      "[EVAL] Sharpe Debug: No volatility or insufficient data.\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: -2.96 | Asset: 970,442.48\n",
      "[TRADE] Step 2 | Reward: -3.26 | Asset: 967,407.60\n",
      "[TRADE] Step 3 | Reward: -6.37 | Asset: 936,274.91\n",
      "[TRADE] Step 4 | Reward: -7.10 | Asset: 928,952.18\n",
      "[TRADE] Step 5 | Reward: -7.38 | Asset: 926,231.58\n",
      "[TRADE] Step 56 | Reward: -4.54 | Asset: 954,645.64\n",
      "[TRADE] Step 57 | Reward: -4.58 | Asset: 954,181.48\n",
      "[TRADE] Step 58 | Reward: -4.72 | Asset: 952,814.48\n",
      "[TRADE] Step 59 | Reward: -3.38 | Asset: 966,226.44\n",
      "[TRADE] Step 60 | Reward: -3.38 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(954645.6376456294), np.float64(954181.4760889194), np.float64(952814.4839979121), np.float64(966226.4376572942), 1000000.0]\n",
      "[DEBUG] total reward: -3.377356026787311\n",
      "✅ Best model: PPO with Sharpe 0.5306\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                   NaN\n",
      "1970-01-01 00:00:00.000000001+00:00   -0.003127\n",
      "1970-01-01 00:00:00.000000002+00:00   -0.032182\n",
      "1970-01-01 00:00:00.000000003+00:00   -0.007821\n",
      "1970-01-01 00:00:00.000000004+00:00   -0.002929\n",
      "1970-01-01 00:00:00.000000005+00:00   -0.031040\n",
      "1970-01-01 00:00:00.000000006+00:00   -0.010374\n",
      "1970-01-01 00:00:00.000000007+00:00    0.021383\n",
      "1970-01-01 00:00:00.000000008+00:00   -0.034210\n",
      "1970-01-01 00:00:00.000000009+00:00    0.004002\n",
      "1970-01-01 00:00:00.000000010+00:00   -0.022254\n",
      "1970-01-01 00:00:00.000000011+00:00    0.064496\n",
      "1970-01-01 00:00:00.000000012+00:00   -0.000065\n",
      "1970-01-01 00:00:00.000000013+00:00   -0.000364\n",
      "1970-01-01 00:00:00.000000014+00:00   -0.019045\n",
      "1970-01-01 00:00:00.000000015+00:00    0.021102\n",
      "1970-01-01 00:00:00.000000016+00:00    0.026305\n",
      "1970-01-01 00:00:00.000000017+00:00    0.007903\n",
      "1970-01-01 00:00:00.000000018+00:00   -0.014170\n",
      "1970-01-01 00:00:00.000000019+00:00   -0.010322\n",
      "1970-01-01 00:00:00.000000020+00:00   -0.012726\n",
      "1970-01-01 00:00:00.000000021+00:00   -0.009604\n",
      "1970-01-01 00:00:00.000000022+00:00   -0.011983\n",
      "1970-01-01 00:00:00.000000023+00:00   -0.029063\n",
      "1970-01-01 00:00:00.000000024+00:00    0.001455\n",
      "1970-01-01 00:00:00.000000025+00:00    0.002535\n",
      "1970-01-01 00:00:00.000000026+00:00    0.054767\n",
      "1970-01-01 00:00:00.000000027+00:00   -0.007617\n",
      "1970-01-01 00:00:00.000000028+00:00    0.029086\n",
      "1970-01-01 00:00:00.000000029+00:00    0.048215\n",
      "1970-01-01 00:00:00.000000030+00:00   -0.008143\n",
      "1970-01-01 00:00:00.000000031+00:00    0.000737\n",
      "1970-01-01 00:00:00.000000032+00:00   -0.017705\n",
      "1970-01-01 00:00:00.000000033+00:00   -0.048171\n",
      "1970-01-01 00:00:00.000000034+00:00   -0.035494\n",
      "1970-01-01 00:00:00.000000035+00:00    0.004574\n",
      "1970-01-01 00:00:00.000000036+00:00    0.021833\n",
      "1970-01-01 00:00:00.000000037+00:00    0.012245\n",
      "1970-01-01 00:00:00.000000038+00:00    0.021141\n",
      "1970-01-01 00:00:00.000000039+00:00   -0.018727\n",
      "1970-01-01 00:00:00.000000040+00:00    0.043877\n",
      "1970-01-01 00:00:00.000000041+00:00   -0.005032\n",
      "1970-01-01 00:00:00.000000042+00:00   -0.008241\n",
      "1970-01-01 00:00:00.000000043+00:00    0.003196\n",
      "1970-01-01 00:00:00.000000044+00:00   -0.003487\n",
      "1970-01-01 00:00:00.000000045+00:00    0.001284\n",
      "1970-01-01 00:00:00.000000046+00:00    0.006777\n",
      "1970-01-01 00:00:00.000000047+00:00   -0.038068\n",
      "1970-01-01 00:00:00.000000048+00:00    0.002146\n",
      "1970-01-01 00:00:00.000000049+00:00    0.033006\n",
      "1970-01-01 00:00:00.000000050+00:00    0.043319\n",
      "1970-01-01 00:00:00.000000051+00:00   -0.000870\n",
      "1970-01-01 00:00:00.000000052+00:00   -0.009899\n",
      "1970-01-01 00:00:00.000000053+00:00   -0.013537\n",
      "1970-01-01 00:00:00.000000054+00:00   -0.006313\n",
      "1970-01-01 00:00:00.000000055+00:00   -0.004308\n",
      "1970-01-01 00:00:00.000000056+00:00   -0.000486\n",
      "1970-01-01 00:00:00.000000057+00:00   -0.001433\n",
      "1970-01-01 00:00:00.000000058+00:00    0.014076\n",
      "1970-01-01 00:00:00.000000059+00:00    0.034954\n",
      "Name: daily_return, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: 0.00077\n",
      "   Std return : 0.02330\n",
      "   Sharpe     : 0.52678\n",
      " Rolling window_9: 2022-01-06 to 2022-11-06\n",
      " Window 9\n",
      "  Train window: 2022-01-06 to 2022-07-06 — 181 days\n",
      "  Val window  : 2022-07-07 to 2022-09-06   — 61 days\n",
      "  Trade window: 2022-09-07 to 2022-11-06 — 60 days\n",
      "count    60.000000\n",
      "mean     -0.000634\n",
      "std       0.030387\n",
      "min      -0.103612\n",
      "25%      -0.010413\n",
      "50%      -0.003826\n",
      "75%       0.012252\n",
      "max       0.084782\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1394 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1168         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037339758 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.005847931 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1077        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004516238 |\n",
      "|    clip_fraction        | 0.0511      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.006415844 |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 63.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1075        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006190071 |\n",
      "|    clip_fraction        | 0.0365      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.002158165 |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 42.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1045         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035901684 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0061227083 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.6         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 59.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1023        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005737408 |\n",
      "|    clip_fraction        | 0.0484      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.012706399 |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -0.15 | Asset: 998,535.49\n",
      "[Validation] Step 2 | Reward: -0.16 | Asset: 998,417.14\n",
      "[Validation] Step 3 | Reward: -3.46 | Asset: 965,373.57\n",
      "[Validation] Step 4 | Reward: -4.19 | Asset: 958,071.48\n",
      "[Validation] Step 5 | Reward: -7.40 | Asset: 925,955.91\n",
      "[Validation] Step 57 | Reward: -7.79 | Asset: 922,078.09\n",
      "[Validation] Step 58 | Reward: -8.35 | Asset: 916,468.15\n",
      "[Validation] Step 59 | Reward: -8.36 | Asset: 916,376.92\n",
      "[Validation] Step 60 | Reward: -9.25 | Asset: 907,514.84\n",
      "[Validation] Step 61 | Reward: -9.25 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(922078.0856757539), np.float64(916468.1471197539), np.float64(916376.9203797539), np.float64(907514.8397497539), 1000000.0]\n",
      "[DEBUG] total reward: -9.248515731203952\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -0.10 | Asset: 998,993.59\n",
      "[Validation] Step 2 | Reward: -0.10 | Asset: 998,988.41\n",
      "[Validation] Step 3 | Reward: -0.10 | Asset: 998,988.41\n",
      "[Validation] Step 4 | Reward: -0.10 | Asset: 998,988.41\n",
      "[Validation] Step 5 | Reward: -0.10 | Asset: 998,988.41\n",
      "[Validation] Step 57 | Reward: -0.10 | Asset: 998,988.41\n",
      "[Validation] Step 58 | Reward: -0.10 | Asset: 998,988.41\n",
      "[Validation] Step 59 | Reward: -0.10 | Asset: 998,988.41\n",
      "[Validation] Step 60 | Reward: -0.10 | Asset: 998,988.41\n",
      "[Validation] Step 61 | Reward: -0.10 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(998988.4117389172), np.float64(998988.4117389172), np.float64(998988.4117389172), np.float64(998988.4117389172), 1000000.0]\n",
      "[DEBUG] total reward: -0.1011588231776841\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -0.24 | Asset: 997,642.63\n",
      "[Validation] Step 2 | Reward: -0.18 | Asset: 998,226.48\n",
      "[Validation] Step 3 | Reward: -1.64 | Asset: 983,616.31\n",
      "[Validation] Step 4 | Reward: -4.52 | Asset: 954,820.63\n",
      "[Validation] Step 5 | Reward: -7.41 | Asset: 925,899.67\n",
      "[Validation] Step 57 | Reward: 35.21 | Asset: 1,352,106.86\n",
      "[Validation] Step 58 | Reward: 33.68 | Asset: 1,336,757.24\n",
      "[Validation] Step 59 | Reward: 35.55 | Asset: 1,355,478.80\n",
      "[Validation] Step 60 | Reward: 38.85 | Asset: 1,388,528.96\n",
      "[Validation] Step 61 | Reward: 38.85 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(1352106.8556499998), np.float64(1336757.23565), np.float64(1355478.79565), np.float64(1388528.95565), 1000000.0]\n",
      "[DEBUG] total reward: 38.852894723415375\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[TRADE] Step 2 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[TRADE] Step 3 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[TRADE] Step 4 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[TRADE] Step 5 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[TRADE] Step 56 | Reward: 0.36 | Asset: 1,003,555.13\n",
      "[TRADE] Step 57 | Reward: 0.36 | Asset: 1,003,555.13\n",
      "[TRADE] Step 58 | Reward: 0.36 | Asset: 1,003,555.13\n",
      "[TRADE] Step 59 | Reward: 0.36 | Asset: 1,003,555.13\n",
      "[TRADE] Step 60 | Reward: 0.36 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1003555.1337685434), np.float64(1003555.1337685434), np.float64(1003555.1337685434), np.float64(1003555.1337685434), 1000000.0]\n",
      "[DEBUG] total reward: 0.35551338270306587\n",
      "✅ Best model: A2C with Sharpe 2.0387\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                   NaN\n",
      "1970-01-01 00:00:00.000000001+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000002+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000003+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000004+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000005+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000006+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000007+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000008+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000009+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000010+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000011+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000012+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000013+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000014+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000015+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000016+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000017+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000018+00:00    0.003567\n",
      "1970-01-01 00:00:00.000000019+00:00   -0.000011\n",
      "1970-01-01 00:00:00.000000020+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000021+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000022+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000023+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000024+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000025+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000026+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000027+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000028+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000029+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000030+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000031+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000032+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000033+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000034+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000035+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000036+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000037+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000038+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000039+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000040+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000041+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000042+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000043+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000044+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000045+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000046+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000047+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000048+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000049+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000050+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000051+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000052+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000053+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000054+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000055+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000056+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000057+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000058+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000059+00:00   -0.003543\n",
      "Name: daily_return, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: 0.00000\n",
      "   Std return : 0.00066\n",
      "   Sharpe     : 0.00515\n",
      " Rolling window_10: 2022-04-06 to 2023-02-06\n",
      " Window 10\n",
      "  Train window: 2022-04-06 to 2022-10-06 — 183 days\n",
      "  Val window  : 2022-10-07 to 2022-12-06   — 60 days\n",
      "  Trade window: 2022-12-07 to 2023-02-06 — 61 days\n",
      "count    59.000000\n",
      "mean     -0.001749\n",
      "std       0.032562\n",
      "min      -0.143671\n",
      "25%      -0.013106\n",
      "50%      -0.002350\n",
      "75%       0.011909\n",
      "max       0.110122\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1384 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1255         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072535537 |\n",
      "|    clip_fraction        | 0.0556       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.015937805 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 39.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1159         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007224534  |\n",
      "|    clip_fraction        | 0.0563       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0060935616 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 36.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1092        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006200962 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.01229918  |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1088         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060981326 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.009194195  |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 29.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1093        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004569004 |\n",
      "|    clip_fraction        | 0.0332      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.008104801 |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 2 | Reward: 0.06 | Asset: 1,000,620.40\n",
      "[Validation] Step 3 | Reward: 0.06 | Asset: 1,000,557.32\n",
      "[Validation] Step 4 | Reward: 0.06 | Asset: 1,000,557.32\n",
      "[Validation] Step 5 | Reward: 0.06 | Asset: 1,000,557.32\n",
      "[Validation] Step 56 | Reward: -8.29 | Asset: 917,087.02\n",
      "[Validation] Step 57 | Reward: -10.52 | Asset: 894,810.84\n",
      "[Validation] Step 58 | Reward: -8.51 | Asset: 914,870.11\n",
      "[Validation] Step 59 | Reward: -9.45 | Asset: 905,499.75\n",
      "[Validation] Step 60 | Reward: -9.45 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(917087.0156180729), np.float64(894810.8384656546), np.float64(914870.1105164267), np.float64(905499.7530038108), 1000000.0]\n",
      "[DEBUG] total reward: -9.45002534345258\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 2 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 3 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 4 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 5 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 56 | Reward: -0.04 | Asset: 999,645.83\n",
      "[Validation] Step 57 | Reward: -0.04 | Asset: 999,645.83\n",
      "[Validation] Step 58 | Reward: -0.04 | Asset: 999,645.83\n",
      "[Validation] Step 59 | Reward: -0.04 | Asset: 999,645.83\n",
      "[Validation] Step 60 | Reward: -0.04 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(999645.8260863128), np.float64(999645.8260863128), np.float64(999645.8260863128), np.float64(999645.8260863128), 1000000.0]\n",
      "[DEBUG] total reward: -0.035417391918599606\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -0.58 | Asset: 994,181.77\n",
      "[Validation] Step 2 | Reward: -0.47 | Asset: 995,255.83\n",
      "[Validation] Step 3 | Reward: -2.04 | Asset: 979,591.18\n",
      "[Validation] Step 4 | Reward: -2.41 | Asset: 975,925.81\n",
      "[Validation] Step 5 | Reward: -1.92 | Asset: 980,797.84\n",
      "[Validation] Step 56 | Reward: -12.44 | Asset: 875,595.55\n",
      "[Validation] Step 57 | Reward: -13.50 | Asset: 865,011.01\n",
      "[Validation] Step 58 | Reward: -12.37 | Asset: 876,256.51\n",
      "[Validation] Step 59 | Reward: -13.09 | Asset: 869,149.66\n",
      "[Validation] Step 60 | Reward: -13.09 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(875595.5465410001), np.float64(865011.0065410001), np.float64(876256.5065410001), np.float64(869149.656541), 1000000.0]\n",
      "[DEBUG] total reward: -13.08503468229901\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: 2.28 | Asset: 1,022,760.80\n",
      "[TRADE] Step 2 | Reward: 1.71 | Asset: 1,017,123.94\n",
      "[TRADE] Step 3 | Reward: 1.71 | Asset: 1,017,060.81\n",
      "[TRADE] Step 4 | Reward: 1.46 | Asset: 1,014,556.85\n",
      "[TRADE] Step 5 | Reward: 2.19 | Asset: 1,021,918.87\n",
      "[TRADE] Step 57 | Reward: 39.24 | Asset: 1,392,386.36\n",
      "[TRADE] Step 58 | Reward: 38.90 | Asset: 1,389,021.00\n",
      "[TRADE] Step 59 | Reward: 38.28 | Asset: 1,382,822.46\n",
      "[TRADE] Step 60 | Reward: 35.96 | Asset: 1,359,580.59\n",
      "[TRADE] Step 61 | Reward: 35.96 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(1392386.3638240001), np.float64(1389021.0038240002), np.float64(1382822.4638240002), np.float64(1359580.593824), 1000000.0]\n",
      "[DEBUG] total reward: 35.958059404976666\n",
      "✅ Best model: DDPG with Sharpe 0.3320\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                   NaN\n",
      "1970-01-01 00:00:00.000000001+00:00   -0.005511\n",
      "1970-01-01 00:00:00.000000002+00:00   -0.000062\n",
      "1970-01-01 00:00:00.000000003+00:00   -0.002462\n",
      "1970-01-01 00:00:00.000000004+00:00    0.007256\n",
      "                                         ...   \n",
      "1970-01-01 00:00:00.000000056+00:00   -0.010222\n",
      "1970-01-01 00:00:00.000000057+00:00   -0.002417\n",
      "1970-01-01 00:00:00.000000058+00:00   -0.004463\n",
      "1970-01-01 00:00:00.000000059+00:00   -0.016808\n",
      "1970-01-01 00:00:00.000000060+00:00   -0.264479\n",
      "Name: daily_return, Length: 61, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: 0.00055\n",
      "   Std return : 0.04029\n",
      "   Sharpe     : 0.21569\n",
      " Rolling window_11: 2022-07-06 to 2023-05-06\n",
      " Window 11\n",
      "  Train window: 2022-07-06 to 2023-01-06 — 184 days\n",
      "  Val window  : 2023-01-07 to 2023-03-06   — 58 days\n",
      "  Trade window: 2023-03-07 to 2023-05-06 — 60 days\n",
      "count    57.000000\n",
      "mean      0.005204\n",
      "std       0.026949\n",
      "min      -0.051668\n",
      "25%      -0.009085\n",
      "50%      -0.000822\n",
      "75%       0.019549\n",
      "max       0.094438\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1329 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1153         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025226544 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.002354741 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 32.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1085         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044414857 |\n",
      "|    clip_fraction        | 0.0374       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.0008915663 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 27.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1033        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004596449 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.010477841 |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0037     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1041         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026585143 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.021030247  |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 21.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1002         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018022053 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.019984663  |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.000306    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 22.7         |\n",
      "------------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 0.02 | Asset: 1,000,172.95\n",
      "[Validation] Step 2 | Reward: 0.02 | Asset: 1,000,172.09\n",
      "[Validation] Step 3 | Reward: 1.53 | Asset: 1,015,291.66\n",
      "[Validation] Step 4 | Reward: 4.45 | Asset: 1,044,549.73\n",
      "[Validation] Step 5 | Reward: 4.55 | Asset: 1,045,527.52\n",
      "[Validation] Step 54 | Reward: 22.50 | Asset: 1,225,011.12\n",
      "[Validation] Step 55 | Reward: 22.35 | Asset: 1,223,533.49\n",
      "[Validation] Step 56 | Reward: 22.35 | Asset: 1,223,530.60\n",
      "[Validation] Step 57 | Reward: 22.79 | Asset: 1,227,923.09\n",
      "[Validation] Step 58 | Reward: 22.79 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 58\n",
      "[DEBUG] Last 5 values: [np.float64(1225011.1172843673), np.float64(1223533.4886798917), np.float64(1223530.5954177596), np.float64(1227923.088165803), 1000000.0]\n",
      "[DEBUG] total reward: 22.792309097792895\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 0.26 | Asset: 1,002,596.36\n",
      "[Validation] Step 2 | Reward: 0.84 | Asset: 1,008,446.53\n",
      "[Validation] Step 3 | Reward: 2.33 | Asset: 1,023,284.51\n",
      "[Validation] Step 4 | Reward: 3.37 | Asset: 1,033,712.22\n",
      "[Validation] Step 5 | Reward: 4.15 | Asset: 1,041,546.81\n",
      "[Validation] Step 54 | Reward: 17.79 | Asset: 1,177,856.63\n",
      "[Validation] Step 55 | Reward: 12.18 | Asset: 1,121,827.42\n",
      "[Validation] Step 56 | Reward: 12.01 | Asset: 1,120,110.33\n",
      "[Validation] Step 57 | Reward: 11.92 | Asset: 1,119,245.72\n",
      "[Validation] Step 58 | Reward: 11.92 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 58\n",
      "[DEBUG] Last 5 values: [np.float64(1177856.629974034), np.float64(1121827.4200325515), np.float64(1120110.3255855304), np.float64(1119245.7197813604), 1000000.0]\n",
      "[DEBUG] total reward: 11.924571365118027\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 0.26 | Asset: 1,002,596.36\n",
      "[Validation] Step 2 | Reward: 0.86 | Asset: 1,008,629.46\n",
      "[Validation] Step 3 | Reward: 1.32 | Asset: 1,013,185.25\n",
      "[Validation] Step 4 | Reward: 3.47 | Asset: 1,034,679.90\n",
      "[Validation] Step 5 | Reward: 4.79 | Asset: 1,047,931.00\n",
      "[Validation] Step 54 | Reward: 21.01 | Asset: 1,210,057.70\n",
      "[Validation] Step 55 | Reward: 15.25 | Asset: 1,152,504.76\n",
      "[Validation] Step 56 | Reward: 15.05 | Asset: 1,150,508.28\n",
      "[Validation] Step 57 | Reward: 14.89 | Asset: 1,148,930.18\n",
      "[Validation] Step 58 | Reward: 14.89 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 58\n",
      "[DEBUG] Last 5 values: [np.float64(1210057.70284), np.float64(1152504.76284), np.float64(1150508.28284), np.float64(1148930.18284), 1000000.0]\n",
      "[DEBUG] total reward: 14.893018174916506\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: -2.23 | Asset: 977,736.71\n",
      "[TRADE] Step 2 | Reward: -8.27 | Asset: 917,291.81\n",
      "[TRADE] Step 3 | Reward: -9.22 | Asset: 907,772.96\n",
      "[TRADE] Step 4 | Reward: -7.85 | Asset: 921,499.76\n",
      "[TRADE] Step 5 | Reward: -6.78 | Asset: 932,228.99\n",
      "[TRADE] Step 56 | Reward: 3.48 | Asset: 1,034,829.11\n",
      "[TRADE] Step 57 | Reward: 4.66 | Asset: 1,046,619.55\n",
      "[TRADE] Step 58 | Reward: 3.99 | Asset: 1,039,897.54\n",
      "[TRADE] Step 59 | Reward: 6.36 | Asset: 1,063,588.28\n",
      "[TRADE] Step 60 | Reward: 6.36 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1034829.113759295), np.float64(1046619.5530413142), np.float64(1039897.5382033918), np.float64(1063588.2805919265), 1000000.0]\n",
      "[DEBUG] total reward: 6.358828092576005\n",
      "✅ Best model: PPO with Sharpe 0.2519\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                   NaN\n",
      "1970-01-01 00:00:00.000000001+00:00   -0.061821\n",
      "1970-01-01 00:00:00.000000002+00:00   -0.010377\n",
      "1970-01-01 00:00:00.000000003+00:00    0.015121\n",
      "1970-01-01 00:00:00.000000004+00:00    0.011643\n",
      "1970-01-01 00:00:00.000000005+00:00    0.095233\n",
      "1970-01-01 00:00:00.000000006+00:00    0.022910\n",
      "1970-01-01 00:00:00.000000007+00:00   -0.015663\n",
      "1970-01-01 00:00:00.000000008+00:00   -0.000034\n",
      "1970-01-01 00:00:00.000000009+00:00    0.001889\n",
      "1970-01-01 00:00:00.000000010+00:00   -0.003469\n",
      "1970-01-01 00:00:00.000000011+00:00    0.033695\n",
      "1970-01-01 00:00:00.000000012+00:00   -0.013337\n",
      "1970-01-01 00:00:00.000000013+00:00    0.019187\n",
      "1970-01-01 00:00:00.000000014+00:00   -0.033793\n",
      "1970-01-01 00:00:00.000000015+00:00    0.014998\n",
      "1970-01-01 00:00:00.000000016+00:00   -0.005875\n",
      "1970-01-01 00:00:00.000000017+00:00   -0.000016\n",
      "1970-01-01 00:00:00.000000018+00:00    0.003060\n",
      "1970-01-01 00:00:00.000000019+00:00   -0.029889\n",
      "1970-01-01 00:00:00.000000020+00:00    0.009603\n",
      "1970-01-01 00:00:00.000000021+00:00    0.033257\n",
      "1970-01-01 00:00:00.000000022+00:00   -0.003096\n",
      "1970-01-01 00:00:00.000000023+00:00    0.001025\n",
      "1970-01-01 00:00:00.000000024+00:00   -0.000031\n",
      "1970-01-01 00:00:00.000000025+00:00   -0.000008\n",
      "1970-01-01 00:00:00.000000026+00:00    0.000000\n",
      "1970-01-01 00:00:00.000000027+00:00    0.003403\n",
      "1970-01-01 00:00:00.000000028+00:00    0.002520\n",
      "1970-01-01 00:00:00.000000029+00:00   -0.008326\n",
      "1970-01-01 00:00:00.000000030+00:00   -0.004491\n",
      "1970-01-01 00:00:00.000000031+00:00   -0.003174\n",
      "1970-01-01 00:00:00.000000032+00:00    0.002154\n",
      "1970-01-01 00:00:00.000000033+00:00    0.010623\n",
      "1970-01-01 00:00:00.000000034+00:00   -0.002262\n",
      "1970-01-01 00:00:00.000000035+00:00    0.005639\n",
      "1970-01-01 00:00:00.000000036+00:00    0.029611\n",
      "1970-01-01 00:00:00.000000037+00:00    0.017445\n",
      "1970-01-01 00:00:00.000000038+00:00   -0.005461\n",
      "1970-01-01 00:00:00.000000039+00:00    0.004784\n",
      "1970-01-01 00:00:00.000000040+00:00   -0.026144\n",
      "1970-01-01 00:00:00.000000041+00:00    0.026006\n",
      "1970-01-01 00:00:00.000000042+00:00   -0.060155\n",
      "1970-01-01 00:00:00.000000043+00:00   -0.012467\n",
      "1970-01-01 00:00:00.000000044+00:00   -0.038638\n",
      "1970-01-01 00:00:00.000000045+00:00    0.019204\n",
      "1970-01-01 00:00:00.000000046+00:00   -0.007935\n",
      "1970-01-01 00:00:00.000000047+00:00   -0.003379\n",
      "1970-01-01 00:00:00.000000048+00:00    0.002443\n",
      "1970-01-01 00:00:00.000000049+00:00   -0.000019\n",
      "1970-01-01 00:00:00.000000050+00:00    0.036941\n",
      "1970-01-01 00:00:00.000000051+00:00   -0.004987\n",
      "1970-01-01 00:00:00.000000052+00:00    0.002314\n",
      "1970-01-01 00:00:00.000000053+00:00   -0.001688\n",
      "1970-01-01 00:00:00.000000054+00:00   -0.004114\n",
      "1970-01-01 00:00:00.000000055+00:00    0.007260\n",
      "1970-01-01 00:00:00.000000056+00:00    0.011394\n",
      "1970-01-01 00:00:00.000000057+00:00   -0.006423\n",
      "1970-01-01 00:00:00.000000058+00:00    0.022782\n",
      "1970-01-01 00:00:00.000000059+00:00   -0.059787\n",
      "Name: daily_return, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: 0.00067\n",
      "   Std return : 0.02408\n",
      "   Sharpe     : 0.43897\n",
      " Rolling window_12: 2022-10-06 to 2023-08-06\n",
      " Window 12\n",
      "  Train window: 2022-10-06 to 2023-04-06 — 182 days\n",
      "  Val window  : 2023-04-07 to 2023-06-06   — 60 days\n",
      "  Trade window: 2023-06-07 to 2023-08-06 — 60 days\n",
      "count    59.000000\n",
      "mean     -0.001111\n",
      "std       0.020558\n",
      "min      -0.053956\n",
      "25%      -0.012131\n",
      "50%      -0.001122\n",
      "75%       0.010958\n",
      "max       0.045220\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1283 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1069         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007960129  |\n",
      "|    clip_fraction        | 0.0526       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.022327065 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.8         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 47.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1053          |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 5             |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0019006517  |\n",
      "|    clip_fraction        | 0.0264        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | -0.0023149252 |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.8          |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00124      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 45.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1064         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042852135 |\n",
      "|    clip_fraction        | 0.0495       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0021978617 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.8         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 43           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1064         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038441326 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0024433136 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 47.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1057        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005457474 |\n",
      "|    clip_fraction        | 0.0355      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.019355595 |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 0.08 | Asset: 1,000,843.04\n",
      "[Validation] Step 2 | Reward: 0.19 | Asset: 1,001,857.97\n",
      "[Validation] Step 3 | Reward: 1.02 | Asset: 1,010,217.62\n",
      "[Validation] Step 4 | Reward: 1.96 | Asset: 1,019,616.45\n",
      "[Validation] Step 5 | Reward: 1.68 | Asset: 1,016,753.06\n",
      "[Validation] Step 56 | Reward: -9.33 | Asset: 906,697.77\n",
      "[Validation] Step 57 | Reward: -9.91 | Asset: 900,918.89\n",
      "[Validation] Step 58 | Reward: -9.76 | Asset: 902,427.94\n",
      "[Validation] Step 59 | Reward: -9.78 | Asset: 902,157.75\n",
      "[Validation] Step 60 | Reward: -9.78 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(906697.7725551638), np.float64(900918.8884496674), np.float64(902427.9423547634), np.float64(902157.7522376057), 1000000.0]\n",
      "[DEBUG] total reward: -9.784224830546009\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -0.06 | Asset: 999,446.79\n",
      "[Validation] Step 2 | Reward: 1.25 | Asset: 1,012,492.07\n",
      "[Validation] Step 3 | Reward: 5.80 | Asset: 1,057,977.04\n",
      "[Validation] Step 4 | Reward: 7.57 | Asset: 1,075,711.11\n",
      "[Validation] Step 5 | Reward: 6.66 | Asset: 1,066,550.73\n",
      "[Validation] Step 56 | Reward: -2.12 | Asset: 978,803.61\n",
      "[Validation] Step 57 | Reward: -2.75 | Asset: 972,473.19\n",
      "[Validation] Step 58 | Reward: -2.61 | Asset: 973,905.43\n",
      "[Validation] Step 59 | Reward: -7.52 | Asset: 924,820.94\n",
      "[Validation] Step 60 | Reward: -7.52 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(978803.6080063327), np.float64(972473.1859793551), np.float64(973905.4329523165), np.float64(924820.9395962985), 1000000.0]\n",
      "[DEBUG] total reward: -7.517905469983816\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -0.15 | Asset: 998,491.36\n",
      "[Validation] Step 2 | Reward: 0.05 | Asset: 1,000,492.87\n",
      "[Validation] Step 3 | Reward: 1.59 | Asset: 1,015,858.29\n",
      "[Validation] Step 4 | Reward: 0.77 | Asset: 1,007,703.18\n",
      "[Validation] Step 5 | Reward: 2.14 | Asset: 1,021,449.28\n",
      "[Validation] Step 56 | Reward: 1.57 | Asset: 1,015,745.43\n",
      "[Validation] Step 57 | Reward: 0.80 | Asset: 1,007,967.59\n",
      "[Validation] Step 58 | Reward: 0.69 | Asset: 1,006,876.99\n",
      "[Validation] Step 59 | Reward: -3.54 | Asset: 964,577.67\n",
      "[Validation] Step 60 | Reward: -3.54 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1015745.429152), np.float64(1007967.5891519999), np.float64(1006876.9891519999), np.float64(964577.669152), 1000000.0]\n",
      "[DEBUG] total reward: -3.5422330647706985\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: 0.13 | Asset: 1,001,332.68\n",
      "[TRADE] Step 2 | Reward: 0.03 | Asset: 1,000,260.22\n",
      "[TRADE] Step 3 | Reward: -2.64 | Asset: 973,589.82\n",
      "[TRADE] Step 4 | Reward: -2.59 | Asset: 974,064.30\n",
      "[TRADE] Step 5 | Reward: -3.10 | Asset: 968,951.78\n",
      "[TRADE] Step 56 | Reward: 2.31 | Asset: 1,023,057.50\n",
      "[TRADE] Step 57 | Reward: 2.08 | Asset: 1,020,783.46\n",
      "[TRADE] Step 58 | Reward: 1.77 | Asset: 1,017,680.98\n",
      "[TRADE] Step 59 | Reward: 2.12 | Asset: 1,021,155.98\n",
      "[TRADE] Step 60 | Reward: 2.12 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1023057.497308), np.float64(1020783.457308), np.float64(1017680.977308), np.float64(1021155.977308), 1000000.0]\n",
      "[DEBUG] total reward: 2.115597000811249\n",
      "✅ Best model: DDPG with Sharpe 0.2035\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                   NaN\n",
      "1970-01-01 00:00:00.000000001+00:00   -0.001071\n",
      "1970-01-01 00:00:00.000000002+00:00   -0.026663\n",
      "1970-01-01 00:00:00.000000003+00:00    0.000487\n",
      "1970-01-01 00:00:00.000000004+00:00   -0.005249\n",
      "1970-01-01 00:00:00.000000005+00:00   -0.001416\n",
      "1970-01-01 00:00:00.000000006+00:00   -0.051240\n",
      "1970-01-01 00:00:00.000000007+00:00    0.009697\n",
      "1970-01-01 00:00:00.000000008+00:00    0.030568\n",
      "1970-01-01 00:00:00.000000009+00:00    0.005727\n",
      "1970-01-01 00:00:00.000000010+00:00   -0.003941\n",
      "1970-01-01 00:00:00.000000011+00:00    0.009389\n",
      "1970-01-01 00:00:00.000000012+00:00    0.031590\n",
      "1970-01-01 00:00:00.000000013+00:00    0.054193\n",
      "1970-01-01 00:00:00.000000014+00:00   -0.009051\n",
      "1970-01-01 00:00:00.000000015+00:00    0.011014\n",
      "1970-01-01 00:00:00.000000016+00:00   -0.009336\n",
      "1970-01-01 00:00:00.000000017+00:00    0.012714\n",
      "1970-01-01 00:00:00.000000018+00:00   -0.020975\n",
      "1970-01-01 00:00:00.000000019+00:00    0.016465\n",
      "1970-01-01 00:00:00.000000020+00:00   -0.032576\n",
      "1970-01-01 00:00:00.000000021+00:00    0.013112\n",
      "1970-01-01 00:00:00.000000022+00:00    0.044166\n",
      "1970-01-01 00:00:00.000000023+00:00   -0.004804\n",
      "1970-01-01 00:00:00.000000024+00:00    0.006744\n",
      "1970-01-01 00:00:00.000000025+00:00    0.009321\n",
      "1970-01-01 00:00:00.000000026+00:00   -0.009889\n",
      "1970-01-01 00:00:00.000000027+00:00   -0.013345\n",
      "1970-01-01 00:00:00.000000028+00:00   -0.033599\n",
      "1970-01-01 00:00:00.000000029+00:00    0.013400\n",
      "1970-01-01 00:00:00.000000030+00:00   -0.003030\n",
      "1970-01-01 00:00:00.000000031+00:00   -0.001308\n",
      "1970-01-01 00:00:00.000000032+00:00    0.009447\n",
      "1970-01-01 00:00:00.000000033+00:00   -0.001117\n",
      "1970-01-01 00:00:00.000000034+00:00   -0.003450\n",
      "1970-01-01 00:00:00.000000035+00:00    0.070873\n",
      "1970-01-01 00:00:00.000000036+00:00   -0.033253\n",
      "1970-01-01 00:00:00.000000037+00:00   -0.003313\n",
      "1970-01-01 00:00:00.000000038+00:00   -0.004815\n",
      "1970-01-01 00:00:00.000000039+00:00   -0.005676\n",
      "1970-01-01 00:00:00.000000040+00:00   -0.007320\n",
      "1970-01-01 00:00:00.000000041+00:00   -0.004522\n",
      "1970-01-01 00:00:00.000000042+00:00    0.001567\n",
      "1970-01-01 00:00:00.000000043+00:00    0.000074\n",
      "1970-01-01 00:00:00.000000044+00:00   -0.013325\n",
      "1970-01-01 00:00:00.000000045+00:00    0.011898\n",
      "1970-01-01 00:00:00.000000046+00:00   -0.020504\n",
      "1970-01-01 00:00:00.000000047+00:00    0.004140\n",
      "1970-01-01 00:00:00.000000048+00:00    0.007719\n",
      "1970-01-01 00:00:00.000000049+00:00   -0.005726\n",
      "1970-01-01 00:00:00.000000050+00:00    0.006936\n",
      "1970-01-01 00:00:00.000000051+00:00    0.003345\n",
      "1970-01-01 00:00:00.000000052+00:00   -0.009928\n",
      "1970-01-01 00:00:00.000000053+00:00   -0.003034\n",
      "1970-01-01 00:00:00.000000054+00:00    0.009336\n",
      "1970-01-01 00:00:00.000000055+00:00   -0.017917\n",
      "1970-01-01 00:00:00.000000056+00:00   -0.002223\n",
      "1970-01-01 00:00:00.000000057+00:00   -0.003039\n",
      "1970-01-01 00:00:00.000000058+00:00    0.003415\n",
      "1970-01-01 00:00:00.000000059+00:00   -0.020718\n",
      "Name: daily_return, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: 0.00017\n",
      "   Std return : 0.01983\n",
      "   Sharpe     : 0.13517\n",
      " Rolling window_13: 2023-01-06 to 2023-11-06\n",
      " Window 13\n",
      "  Train window: 2023-01-06 to 2023-07-06 — 181 days\n",
      "  Val window  : 2023-07-07 to 2023-09-06   — 61 days\n",
      "  Trade window: 2023-09-07 to 2023-11-06 — 60 days\n",
      "count    60.000000\n",
      "mean     -0.002531\n",
      "std       0.017243\n",
      "min      -0.073135\n",
      "25%      -0.004795\n",
      "50%      -0.001766\n",
      "75%       0.003249\n",
      "max       0.060227\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1300 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1067         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005642238  |\n",
      "|    clip_fraction        | 0.0477       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0050576925 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 28.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1007         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049584005 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0073051453 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 41.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1022         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067617577 |\n",
      "|    clip_fraction        | 0.0502       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.007412672  |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1039         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039008013 |\n",
      "|    clip_fraction        | 0.0347       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.012509823  |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    std                  | 0.99         |\n",
      "|    value_loss           | 33.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1051         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038995375 |\n",
      "|    clip_fraction        | 0.0444       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.011462808  |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    std                  | 0.987        |\n",
      "|    value_loss           | 45.3         |\n",
      "------------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -0.20 | Asset: 997,980.66\n",
      "[Validation] Step 2 | Reward: -0.60 | Asset: 994,015.22\n",
      "[Validation] Step 3 | Reward: -0.43 | Asset: 995,660.07\n",
      "[Validation] Step 4 | Reward: 0.18 | Asset: 1,001,795.32\n",
      "[Validation] Step 5 | Reward: -0.59 | Asset: 994,132.32\n",
      "[Validation] Step 57 | Reward: -9.47 | Asset: 905,325.26\n",
      "[Validation] Step 58 | Reward: -9.11 | Asset: 908,866.57\n",
      "[Validation] Step 59 | Reward: -9.12 | Asset: 908,775.89\n",
      "[Validation] Step 60 | Reward: -9.25 | Asset: 907,498.30\n",
      "[Validation] Step 61 | Reward: -9.25 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(905325.2614395407), np.float64(908866.5746856824), np.float64(908775.8914957977), np.float64(907498.3004257976), 1000000.0]\n",
      "[DEBUG] total reward: -9.250170107930899\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -0.21 | Asset: 997,892.80\n",
      "[Validation] Step 2 | Reward: -0.61 | Asset: 993,890.76\n",
      "[Validation] Step 3 | Reward: 0.22 | Asset: 1,002,182.28\n",
      "[Validation] Step 4 | Reward: 0.89 | Asset: 1,008,887.74\n",
      "[Validation] Step 5 | Reward: 0.10 | Asset: 1,001,043.34\n",
      "[Validation] Step 57 | Reward: -11.00 | Asset: 890,024.64\n",
      "[Validation] Step 58 | Reward: -10.74 | Asset: 892,631.31\n",
      "[Validation] Step 59 | Reward: -11.19 | Asset: 888,087.57\n",
      "[Validation] Step 60 | Reward: -11.24 | Asset: 887,632.71\n",
      "[Validation] Step 61 | Reward: -11.24 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(890024.639069), np.float64(892631.3090690001), np.float64(888087.5690690002), np.float64(887632.7090690001), 1000000.0]\n",
      "[DEBUG] total reward: -11.236729165539145\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -0.20 | Asset: 997,980.66\n",
      "[Validation] Step 2 | Reward: -0.60 | Asset: 994,015.22\n",
      "[Validation] Step 3 | Reward: 0.20 | Asset: 1,002,042.74\n",
      "[Validation] Step 4 | Reward: 0.88 | Asset: 1,008,779.70\n",
      "[Validation] Step 5 | Reward: 0.10 | Asset: 1,001,032.50\n",
      "[Validation] Step 57 | Reward: -14.62 | Asset: 853,832.94\n",
      "[Validation] Step 58 | Reward: -14.28 | Asset: 857,189.04\n",
      "[Validation] Step 59 | Reward: -14.76 | Asset: 852,397.77\n",
      "[Validation] Step 60 | Reward: -14.87 | Asset: 851,278.41\n",
      "[Validation] Step 61 | Reward: -14.87 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(853832.943909), np.float64(857189.043909), np.float64(852397.7739090001), np.float64(851278.413909), 1000000.0]\n",
      "[DEBUG] total reward: -14.872158471494913\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: -1.32 | Asset: 986,809.23\n",
      "[TRADE] Step 2 | Reward: -1.35 | Asset: 986,471.41\n",
      "[TRADE] Step 3 | Reward: -1.58 | Asset: 984,191.41\n",
      "[TRADE] Step 4 | Reward: -4.16 | Asset: 958,385.99\n",
      "[TRADE] Step 5 | Reward: -1.59 | Asset: 984,134.03\n",
      "[TRADE] Step 56 | Reward: 33.00 | Asset: 1,329,990.65\n",
      "[TRADE] Step 57 | Reward: 32.14 | Asset: 1,321,447.87\n",
      "[TRADE] Step 58 | Reward: 33.46 | Asset: 1,334,568.89\n",
      "[TRADE] Step 59 | Reward: 33.27 | Asset: 1,332,661.67\n",
      "[TRADE] Step 60 | Reward: 33.27 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1329990.651), np.float64(1321447.8709999998), np.float64(1334568.8909999998), np.float64(1332661.671), 1000000.0]\n",
      "[DEBUG] total reward: 33.266167890280485\n",
      "✅ Best model: DDPG with Sharpe 0.2286\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                   NaN\n",
      "1970-01-01 00:00:00.000000001+00:00   -0.000342\n",
      "1970-01-01 00:00:00.000000002+00:00   -0.002311\n",
      "1970-01-01 00:00:00.000000003+00:00   -0.026220\n",
      "1970-01-01 00:00:00.000000004+00:00    0.026866\n",
      "1970-01-01 00:00:00.000000005+00:00    0.014746\n",
      "1970-01-01 00:00:00.000000006+00:00    0.011443\n",
      "1970-01-01 00:00:00.000000007+00:00    0.002907\n",
      "1970-01-01 00:00:00.000000008+00:00   -0.001513\n",
      "1970-01-01 00:00:00.000000009+00:00   -0.001208\n",
      "1970-01-01 00:00:00.000000010+00:00    0.008839\n",
      "1970-01-01 00:00:00.000000011+00:00    0.016694\n",
      "1970-01-01 00:00:00.000000012+00:00   -0.003127\n",
      "1970-01-01 00:00:00.000000013+00:00   -0.020488\n",
      "1970-01-01 00:00:00.000000014+00:00    0.000453\n",
      "1970-01-01 00:00:00.000000015+00:00   -0.000157\n",
      "1970-01-01 00:00:00.000000016+00:00   -0.012299\n",
      "1970-01-01 00:00:00.000000017+00:00    0.002145\n",
      "1970-01-01 00:00:00.000000018+00:00   -0.003154\n",
      "1970-01-01 00:00:00.000000019+00:00    0.005758\n",
      "1970-01-01 00:00:00.000000020+00:00    0.024532\n",
      "1970-01-01 00:00:00.000000021+00:00   -0.004226\n",
      "1970-01-01 00:00:00.000000022+00:00    0.002062\n",
      "1970-01-01 00:00:00.000000023+00:00    0.038119\n",
      "1970-01-01 00:00:00.000000024+00:00   -0.017756\n",
      "1970-01-01 00:00:00.000000025+00:00   -0.002470\n",
      "1970-01-01 00:00:00.000000026+00:00    0.012811\n",
      "1970-01-01 00:00:00.000000027+00:00   -0.013226\n",
      "1970-01-01 00:00:00.000000028+00:00    0.018956\n",
      "1970-01-01 00:00:00.000000029+00:00    0.000914\n",
      "1970-01-01 00:00:00.000000030+00:00   -0.001414\n",
      "1970-01-01 00:00:00.000000031+00:00   -0.011686\n",
      "1970-01-01 00:00:00.000000032+00:00   -0.007234\n",
      "1970-01-01 00:00:00.000000033+00:00   -0.018748\n",
      "1970-01-01 00:00:00.000000034+00:00   -0.004303\n",
      "1970-01-01 00:00:00.000000035+00:00    0.003817\n",
      "1970-01-01 00:00:00.000000036+00:00   -0.000354\n",
      "1970-01-01 00:00:00.000000037+00:00    0.011210\n",
      "1970-01-01 00:00:00.000000038+00:00    0.049486\n",
      "1970-01-01 00:00:00.000000039+00:00   -0.003672\n",
      "1970-01-01 00:00:00.000000040+00:00   -0.002668\n",
      "1970-01-01 00:00:00.000000041+00:00    0.013874\n",
      "1970-01-01 00:00:00.000000042+00:00    0.033204\n",
      "1970-01-01 00:00:00.000000043+00:00    0.008099\n",
      "1970-01-01 00:00:00.000000044+00:00    0.002758\n",
      "1970-01-01 00:00:00.000000045+00:00    0.102412\n",
      "1970-01-01 00:00:00.000000046+00:00    0.025741\n",
      "1970-01-01 00:00:00.000000047+00:00    0.016872\n",
      "1970-01-01 00:00:00.000000048+00:00   -0.009967\n",
      "1970-01-01 00:00:00.000000049+00:00   -0.007590\n",
      "1970-01-01 00:00:00.000000050+00:00    0.005566\n",
      "1970-01-01 00:00:00.000000051+00:00    0.013032\n",
      "1970-01-01 00:00:00.000000052+00:00   -0.001479\n",
      "1970-01-01 00:00:00.000000053+00:00    0.004779\n",
      "1970-01-01 00:00:00.000000054+00:00    0.022528\n",
      "1970-01-01 00:00:00.000000055+00:00   -0.013524\n",
      "1970-01-01 00:00:00.000000056+00:00   -0.006423\n",
      "1970-01-01 00:00:00.000000057+00:00    0.009929\n",
      "1970-01-01 00:00:00.000000058+00:00   -0.001429\n",
      "1970-01-01 00:00:00.000000059+00:00   -0.249622\n",
      "Name: daily_return, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: 0.00105\n",
      "   Std return : 0.03835\n",
      "   Sharpe     : 0.43460\n",
      " Rolling window_14: 2023-04-06 to 2024-02-06\n",
      " Window 14\n",
      "  Train window: 2023-04-06 to 2023-10-06 — 183 days\n",
      "  Val window  : 2023-10-07 to 2023-12-06   — 60 days\n",
      "  Trade window: 2023-12-07 to 2024-02-06 — 61 days\n",
      "count    59.000000\n",
      "mean      0.007913\n",
      "std       0.023780\n",
      "min      -0.045491\n",
      "25%      -0.004805\n",
      "50%       0.003723\n",
      "75%       0.014772\n",
      "max       0.100432\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1353 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1067         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059145647 |\n",
      "|    clip_fraction        | 0.0382       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.087362766 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.04         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 8.6          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1081         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006351161  |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0137732625 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.94         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 7.67         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1077         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025352382 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.011259377  |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.24         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 10.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1030        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004715233 |\n",
      "|    clip_fraction        | 0.0278      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.016533315 |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.02        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 9.5         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1003         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005443726  |\n",
      "|    clip_fraction        | 0.0345       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0120488405 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.16         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 10.4         |\n",
      "------------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -0.15 | Asset: 998,515.45\n",
      "[Validation] Step 2 | Reward: -1.33 | Asset: 986,685.11\n",
      "[Validation] Step 3 | Reward: -1.36 | Asset: 986,423.37\n",
      "[Validation] Step 4 | Reward: -3.22 | Asset: 967,797.11\n",
      "[Validation] Step 5 | Reward: -3.64 | Asset: 963,625.07\n",
      "[Validation] Step 56 | Reward: 5.31 | Asset: 1,053,135.76\n",
      "[Validation] Step 57 | Reward: 5.31 | Asset: 1,053,135.76\n",
      "[Validation] Step 58 | Reward: 5.31 | Asset: 1,053,135.76\n",
      "[Validation] Step 59 | Reward: 10.51 | Asset: 1,105,086.28\n",
      "[Validation] Step 60 | Reward: 10.51 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1053135.7615519105), np.float64(1053135.7615519105), np.float64(1053135.7615519105), np.float64(1105086.2838019105), 1000000.0]\n",
      "[DEBUG] total reward: 10.50862826150842\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: -0.15 | Asset: 998,503.84\n",
      "[Validation] Step 2 | Reward: -0.16 | Asset: 998,404.01\n",
      "[Validation] Step 3 | Reward: -0.29 | Asset: 997,138.20\n",
      "[Validation] Step 4 | Reward: -1.85 | Asset: 981,531.95\n",
      "[Validation] Step 5 | Reward: -1.89 | Asset: 981,135.79\n",
      "[Validation] Step 56 | Reward: 20.84 | Asset: 1,208,393.01\n",
      "[Validation] Step 57 | Reward: 22.42 | Asset: 1,224,219.12\n",
      "[Validation] Step 58 | Reward: 28.48 | Asset: 1,284,843.24\n",
      "[Validation] Step 59 | Reward: 28.47 | Asset: 1,284,716.82\n",
      "[Validation] Step 60 | Reward: 28.47 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1208393.0087824818), np.float64(1224219.1199594818), np.float64(1284843.2443294816), np.float64(1284716.8223554816), 1000000.0]\n",
      "[DEBUG] total reward: 28.4716822123155\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 2 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 3 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 4 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 5 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 56 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 57 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 58 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 59 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[Validation] Step 60 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1000000.0), np.float64(1000000.0), np.float64(1000000.0), np.float64(1000000.0), 1000000.0]\n",
      "[DEBUG] total reward: 0.0\n",
      "[EVAL] Sharpe Debug: No volatility or insufficient data.\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: 2.06 | Asset: 1,020,553.78\n",
      "[TRADE] Step 2 | Reward: 2.05 | Asset: 1,020,451.95\n",
      "[TRADE] Step 3 | Reward: 2.16 | Asset: 1,021,618.54\n",
      "[TRADE] Step 4 | Reward: -0.39 | Asset: 996,141.02\n",
      "[TRADE] Step 5 | Reward: -0.53 | Asset: 994,730.96\n",
      "[TRADE] Step 57 | Reward: 4.76 | Asset: 1,047,594.94\n",
      "[TRADE] Step 58 | Reward: 4.73 | Asset: 1,047,292.97\n",
      "[TRADE] Step 59 | Reward: 4.65 | Asset: 1,046,492.80\n",
      "[TRADE] Step 60 | Reward: 4.91 | Asset: 1,049,070.55\n",
      "[TRADE] Step 61 | Reward: 4.91 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(1047594.9404624896), np.float64(1047292.9698624896), np.float64(1046492.8049624896), np.float64(1049070.5470624897), 1000000.0]\n",
      "[DEBUG] total reward: 4.907054248265922\n",
      "✅ Best model: A2C with Sharpe 0.3177\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                   NaN\n",
      "1970-01-01 00:00:00.000000001+00:00   -0.000100\n",
      "1970-01-01 00:00:00.000000002+00:00    0.001143\n",
      "1970-01-01 00:00:00.000000003+00:00   -0.024938\n",
      "1970-01-01 00:00:00.000000004+00:00   -0.001416\n",
      "                                         ...   \n",
      "1970-01-01 00:00:00.000000056+00:00    0.002469\n",
      "1970-01-01 00:00:00.000000057+00:00   -0.000288\n",
      "1970-01-01 00:00:00.000000058+00:00   -0.000764\n",
      "1970-01-01 00:00:00.000000059+00:00    0.002463\n",
      "1970-01-01 00:00:00.000000060+00:00   -0.046775\n",
      "Name: daily_return, Length: 61, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: -0.00015\n",
      "   Std return : 0.01945\n",
      "   Sharpe     : -0.12573\n",
      " Rolling window_15: 2023-07-06 to 2024-05-06\n",
      " Window 15\n",
      "  Train window: 2023-07-06 to 2024-01-06 — 184 days\n",
      "  Val window  : 2024-01-07 to 2024-03-06   — 59 days\n",
      "  Trade window: 2024-03-07 to 2024-05-06 — 60 days\n",
      "count    58.000000\n",
      "mean      0.006933\n",
      "std       0.029123\n",
      "min      -0.074594\n",
      "25%      -0.007094\n",
      "50%       0.004173\n",
      "75%       0.017847\n",
      "max       0.091830\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1396 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1152        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004489105 |\n",
      "|    clip_fraction        | 0.0325      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | -0.03409016 |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1099         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034790225 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.007828355 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 25.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1104          |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 7             |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0057767304  |\n",
      "|    clip_fraction        | 0.0424        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.82         |\n",
      "|    explained_variance   | -0.0003335476 |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.49          |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00395      |\n",
      "|    std                  | 0.992         |\n",
      "|    value_loss           | 18.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1098         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043965164 |\n",
      "|    clip_fraction        | 0.0461       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.0002644062 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 27.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1072         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007940143  |\n",
      "|    clip_fraction        | 0.0562       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0047314763 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 6.80 | Asset: 1,068,019.76\n",
      "[Validation] Step 2 | Reward: 6.95 | Asset: 1,069,472.28\n",
      "[Validation] Step 3 | Reward: 9.59 | Asset: 1,095,870.51\n",
      "[Validation] Step 4 | Reward: 10.14 | Asset: 1,101,440.20\n",
      "[Validation] Step 5 | Reward: 9.30 | Asset: 1,093,021.81\n",
      "[Validation] Step 55 | Reward: 52.99 | Asset: 1,529,908.86\n",
      "[Validation] Step 56 | Reward: 53.80 | Asset: 1,538,009.09\n",
      "[Validation] Step 57 | Reward: 55.97 | Asset: 1,559,657.24\n",
      "[Validation] Step 58 | Reward: 46.95 | Asset: 1,469,520.66\n",
      "[Validation] Step 59 | Reward: 46.95 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 59\n",
      "[DEBUG] Last 5 values: [np.float64(1529908.858182272), np.float64(1538009.0877919476), np.float64(1559657.2424725024), np.float64(1469520.660478603), 1000000.0]\n",
      "[DEBUG] total reward: 46.952065403573215\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 1.09 | Asset: 1,010,879.79\n",
      "[Validation] Step 2 | Reward: 1.36 | Asset: 1,013,626.48\n",
      "[Validation] Step 3 | Reward: 7.12 | Asset: 1,071,175.48\n",
      "[Validation] Step 4 | Reward: 7.49 | Asset: 1,074,942.80\n",
      "[Validation] Step 5 | Reward: 1.53 | Asset: 1,015,296.02\n",
      "[Validation] Step 55 | Reward: 30.76 | Asset: 1,307,556.75\n",
      "[Validation] Step 56 | Reward: 33.13 | Asset: 1,331,283.65\n",
      "[Validation] Step 57 | Reward: 43.92 | Asset: 1,439,190.14\n",
      "[Validation] Step 58 | Reward: 34.42 | Asset: 1,344,160.33\n",
      "[Validation] Step 59 | Reward: 34.42 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 59\n",
      "[DEBUG] Last 5 values: [np.float64(1307556.7523590326), np.float64(1331283.652359033), np.float64(1439190.142359033), np.float64(1344160.3323590327), 1000000.0]\n",
      "[DEBUG] total reward: 34.416033568792045\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 6.80 | Asset: 1,068,019.76\n",
      "[Validation] Step 2 | Reward: 6.79 | Asset: 1,067,912.98\n",
      "[Validation] Step 3 | Reward: 8.10 | Asset: 1,081,038.26\n",
      "[Validation] Step 4 | Reward: 8.09 | Asset: 1,080,930.18\n",
      "[Validation] Step 5 | Reward: -0.15 | Asset: 998,547.05\n",
      "[Validation] Step 55 | Reward: 1.33 | Asset: 1,013,259.76\n",
      "[Validation] Step 56 | Reward: 1.32 | Asset: 1,013,158.53\n",
      "[Validation] Step 57 | Reward: 9.52 | Asset: 1,095,165.38\n",
      "[Validation] Step 58 | Reward: 9.51 | Asset: 1,095,056.19\n",
      "[Validation] Step 59 | Reward: 9.51 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 59\n",
      "[DEBUG] Last 5 values: [np.float64(1013259.7597350011), np.float64(1013158.5272470012), np.float64(1095165.3848950013), np.float64(1095056.1917590012), 1000000.0]\n",
      "[DEBUG] total reward: 9.505618695169687\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: 0.03 | Asset: 1,000,304.74\n",
      "[TRADE] Step 2 | Reward: 0.23 | Asset: 1,002,327.52\n",
      "[TRADE] Step 3 | Reward: 0.54 | Asset: 1,005,418.74\n",
      "[TRADE] Step 4 | Reward: 5.18 | Asset: 1,051,839.74\n",
      "[TRADE] Step 5 | Reward: 3.79 | Asset: 1,037,862.98\n",
      "[TRADE] Step 56 | Reward: -14.08 | Asset: 859,200.88\n",
      "[TRADE] Step 57 | Reward: -9.37 | Asset: 906,325.35\n",
      "[TRADE] Step 58 | Reward: -8.26 | Asset: 917,441.25\n",
      "[TRADE] Step 59 | Reward: -7.86 | Asset: 921,375.51\n",
      "[TRADE] Step 60 | Reward: -7.86 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(859200.8827102858), np.float64(906325.3517656685), np.float64(917441.2529645266), np.float64(921375.5073887402), 1000000.0]\n",
      "[DEBUG] total reward: -7.862450804095715\n",
      "✅ Best model: A2C with Sharpe 0.3077\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                   NaN\n",
      "1970-01-01 00:00:00.000000001+00:00    0.002022\n",
      "1970-01-01 00:00:00.000000002+00:00    0.003084\n",
      "1970-01-01 00:00:00.000000003+00:00    0.046171\n",
      "1970-01-01 00:00:00.000000004+00:00   -0.013288\n",
      "1970-01-01 00:00:00.000000005+00:00    0.016404\n",
      "1970-01-01 00:00:00.000000006+00:00   -0.025836\n",
      "1970-01-01 00:00:00.000000007+00:00   -0.029893\n",
      "1970-01-01 00:00:00.000000008+00:00   -0.059520\n",
      "1970-01-01 00:00:00.000000009+00:00    0.042443\n",
      "1970-01-01 00:00:00.000000010+00:00   -0.022642\n",
      "1970-01-01 00:00:00.000000011+00:00   -0.097414\n",
      "1970-01-01 00:00:00.000000012+00:00    0.108073\n",
      "1970-01-01 00:00:00.000000013+00:00   -0.016411\n",
      "1970-01-01 00:00:00.000000014+00:00   -0.034699\n",
      "1970-01-01 00:00:00.000000015+00:00    0.001583\n",
      "1970-01-01 00:00:00.000000016+00:00    0.046478\n",
      "1970-01-01 00:00:00.000000017+00:00    0.039259\n",
      "1970-01-01 00:00:00.000000018+00:00    0.001523\n",
      "1970-01-01 00:00:00.000000019+00:00   -0.007503\n",
      "1970-01-01 00:00:00.000000020+00:00    0.018803\n",
      "1970-01-01 00:00:00.000000021+00:00   -0.013014\n",
      "1970-01-01 00:00:00.000000022+00:00   -0.003813\n",
      "1970-01-01 00:00:00.000000023+00:00    0.024444\n",
      "1970-01-01 00:00:00.000000024+00:00   -0.022925\n",
      "1970-01-01 00:00:00.000000025+00:00   -0.059964\n",
      "1970-01-01 00:00:00.000000026+00:00    0.007620\n",
      "1970-01-01 00:00:00.000000027+00:00    0.037890\n",
      "1970-01-01 00:00:00.000000028+00:00   -0.009668\n",
      "1970-01-01 00:00:00.000000029+00:00    0.015702\n",
      "1970-01-01 00:00:00.000000030+00:00    0.006886\n",
      "1970-01-01 00:00:00.000000031+00:00    0.032753\n",
      "1970-01-01 00:00:00.000000032+00:00   -0.034576\n",
      "1970-01-01 00:00:00.000000033+00:00    0.021347\n",
      "1970-01-01 00:00:00.000000034+00:00   -0.008762\n",
      "1970-01-01 00:00:00.000000035+00:00   -0.040875\n",
      "1970-01-01 00:00:00.000000036+00:00   -0.047562\n",
      "1970-01-01 00:00:00.000000037+00:00    0.026901\n",
      "1970-01-01 00:00:00.000000038+00:00   -0.033919\n",
      "1970-01-01 00:00:00.000000039+00:00    0.005788\n",
      "1970-01-01 00:00:00.000000040+00:00   -0.039045\n",
      "1970-01-01 00:00:00.000000041+00:00    0.035682\n",
      "1970-01-01 00:00:00.000000042+00:00    0.005399\n",
      "1970-01-01 00:00:00.000000043+00:00    0.017740\n",
      "1970-01-01 00:00:00.000000044+00:00   -0.000018\n",
      "1970-01-01 00:00:00.000000045+00:00    0.028792\n",
      "1970-01-01 00:00:00.000000046+00:00   -0.005943\n",
      "1970-01-01 00:00:00.000000047+00:00   -0.031907\n",
      "1970-01-01 00:00:00.000000048+00:00    0.003263\n",
      "1970-01-01 00:00:00.000000049+00:00   -0.009056\n",
      "1970-01-01 00:00:00.000000050+00:00    0.027806\n",
      "1970-01-01 00:00:00.000000051+00:00    0.000251\n",
      "1970-01-01 00:00:00.000000052+00:00   -0.007187\n",
      "1970-01-01 00:00:00.000000053+00:00   -0.058063\n",
      "1970-01-01 00:00:00.000000054+00:00   -0.020537\n",
      "1970-01-01 00:00:00.000000055+00:00    0.009014\n",
      "1970-01-01 00:00:00.000000056+00:00    0.054847\n",
      "1970-01-01 00:00:00.000000057+00:00    0.012265\n",
      "1970-01-01 00:00:00.000000058+00:00    0.004288\n",
      "1970-01-01 00:00:00.000000059+00:00    0.085334\n",
      "Name: daily_return, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: 0.00061\n",
      "   Std return : 0.03534\n",
      "   Sharpe     : 0.27267\n",
      " Rolling window_16: 2023-10-06 to 2024-08-06\n",
      " Window 16\n",
      "  Train window: 2023-10-06 to 2024-04-06 — 183 days\n",
      "  Val window  : 2024-04-07 to 2024-06-06   — 60 days\n",
      "  Trade window: 2024-06-07 to 2024-08-06 — 60 days\n",
      "count    59.000000\n",
      "mean      0.000854\n",
      "std       0.027164\n",
      "min      -0.050634\n",
      "25%      -0.014405\n",
      "50%      -0.000111\n",
      "75%       0.014089\n",
      "max       0.083109\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1371 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1231          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008053259   |\n",
      "|    clip_fraction        | 0.056         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | -0.0047427416 |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.3          |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00464      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 57.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1194         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025794925 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.002129078  |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.2         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 71.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1170         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033281639 |\n",
      "|    clip_fraction        | 0.0318       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0020816326 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.1         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 90.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1150          |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007335997   |\n",
      "|    clip_fraction        | 0.0573        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | -0.0002604723 |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 36.5          |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00552      |\n",
      "|    std                  | 0.996         |\n",
      "|    value_loss           | 95.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1123         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008302014  |\n",
      "|    clip_fraction        | 0.0649       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0005518794 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.4         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 98.8         |\n",
      "------------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 3.15 | Asset: 1,031,537.44\n",
      "[Validation] Step 2 | Reward: -0.44 | Asset: 995,581.31\n",
      "[Validation] Step 3 | Reward: -0.38 | Asset: 996,167.99\n",
      "[Validation] Step 4 | Reward: -1.33 | Asset: 986,679.23\n",
      "[Validation] Step 5 | Reward: -5.23 | Asset: 947,687.76\n",
      "[Validation] Step 56 | Reward: 1.84 | Asset: 1,018,411.03\n",
      "[Validation] Step 57 | Reward: 2.38 | Asset: 1,023,754.45\n",
      "[Validation] Step 58 | Reward: 4.66 | Asset: 1,046,576.56\n",
      "[Validation] Step 59 | Reward: 5.45 | Asset: 1,054,525.66\n",
      "[Validation] Step 60 | Reward: 5.45 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1018411.0254332488), np.float64(1023754.453760549), np.float64(1046576.5559210934), np.float64(1054525.6629774221), 1000000.0]\n",
      "[DEBUG] total reward: 5.452566901658429\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 3.35 | Asset: 1,033,457.95\n",
      "[Validation] Step 2 | Reward: -0.12 | Asset: 998,819.00\n",
      "[Validation] Step 3 | Reward: 1.96 | Asset: 1,019,610.12\n",
      "[Validation] Step 4 | Reward: 1.09 | Asset: 1,010,862.22\n",
      "[Validation] Step 5 | Reward: -2.96 | Asset: 970,406.28\n",
      "[Validation] Step 56 | Reward: -1.95 | Asset: 980,480.90\n",
      "[Validation] Step 57 | Reward: -0.49 | Asset: 995,100.68\n",
      "[Validation] Step 58 | Reward: 1.93 | Asset: 1,019,291.84\n",
      "[Validation] Step 59 | Reward: 2.73 | Asset: 1,027,274.08\n",
      "[Validation] Step 60 | Reward: 2.73 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(980480.9041560001), np.float64(995100.6841559999), np.float64(1019291.8441560001), np.float64(1027274.084156), 1000000.0]\n",
      "[DEBUG] total reward: 2.727407708967803\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 2.40 | Asset: 1,024,006.46\n",
      "[Validation] Step 2 | Reward: -1.37 | Asset: 986,325.51\n",
      "[Validation] Step 3 | Reward: -0.27 | Asset: 997,326.36\n",
      "[Validation] Step 4 | Reward: -1.48 | Asset: 985,209.64\n",
      "[Validation] Step 5 | Reward: -8.93 | Asset: 910,719.35\n",
      "[Validation] Step 56 | Reward: 6.34 | Asset: 1,063,437.23\n",
      "[Validation] Step 57 | Reward: 5.95 | Asset: 1,059,545.38\n",
      "[Validation] Step 58 | Reward: 7.17 | Asset: 1,071,676.15\n",
      "[Validation] Step 59 | Reward: 8.73 | Asset: 1,087,344.71\n",
      "[Validation] Step 60 | Reward: 8.73 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1063437.230141), np.float64(1059545.3801409998), np.float64(1071676.1501410003), np.float64(1087344.7101409999), 1000000.0]\n",
      "[DEBUG] total reward: 8.734470896422863\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: 0.03 | Asset: 1,000,288.22\n",
      "[TRADE] Step 2 | Reward: 0.52 | Asset: 1,005,217.40\n",
      "[TRADE] Step 3 | Reward: -0.53 | Asset: 994,744.04\n",
      "[TRADE] Step 4 | Reward: -5.15 | Asset: 948,533.12\n",
      "[TRADE] Step 5 | Reward: -3.45 | Asset: 965,549.21\n",
      "[TRADE] Step 56 | Reward: -18.91 | Asset: 810,941.00\n",
      "[TRADE] Step 57 | Reward: -21.24 | Asset: 787,643.13\n",
      "[TRADE] Step 58 | Reward: -27.05 | Asset: 729,454.01\n",
      "[TRADE] Step 59 | Reward: -34.35 | Asset: 656,465.58\n",
      "[TRADE] Step 60 | Reward: -34.35 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(810940.9956600001), np.float64(787643.12566), np.float64(729454.0056600001), np.float64(656465.5756600001), 1000000.0]\n",
      "[DEBUG] total reward: -34.353441786020994\n",
      "✅ Best model: DDPG with Sharpe 0.1171\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                   NaN\n",
      "1970-01-01 00:00:00.000000001+00:00    0.004928\n",
      "1970-01-01 00:00:00.000000002+00:00   -0.010419\n",
      "1970-01-01 00:00:00.000000003+00:00   -0.046455\n",
      "1970-01-01 00:00:00.000000004+00:00    0.017939\n",
      "1970-01-01 00:00:00.000000005+00:00   -0.025462\n",
      "1970-01-01 00:00:00.000000006+00:00    0.003571\n",
      "1970-01-01 00:00:00.000000007+00:00    0.024950\n",
      "1970-01-01 00:00:00.000000008+00:00    0.015587\n",
      "1970-01-01 00:00:00.000000009+00:00   -0.031140\n",
      "1970-01-01 00:00:00.000000010+00:00   -0.007979\n",
      "1970-01-01 00:00:00.000000011+00:00    0.022113\n",
      "1970-01-01 00:00:00.000000012+00:00   -0.013311\n",
      "1970-01-01 00:00:00.000000013+00:00    0.001542\n",
      "1970-01-01 00:00:00.000000014+00:00   -0.006461\n",
      "1970-01-01 00:00:00.000000015+00:00   -0.021392\n",
      "1970-01-01 00:00:00.000000016+00:00   -0.019914\n",
      "1970-01-01 00:00:00.000000017+00:00    0.012570\n",
      "1970-01-01 00:00:00.000000018+00:00   -0.006908\n",
      "1970-01-01 00:00:00.000000019+00:00    0.023413\n",
      "1970-01-01 00:00:00.000000020+00:00   -0.020355\n",
      "1970-01-01 00:00:00.000000021+00:00   -0.000399\n",
      "1970-01-01 00:00:00.000000022+00:00    0.017554\n",
      "1970-01-01 00:00:00.000000023+00:00    0.001174\n",
      "1970-01-01 00:00:00.000000024+00:00   -0.006052\n",
      "1970-01-01 00:00:00.000000025+00:00   -0.036760\n",
      "1970-01-01 00:00:00.000000026+00:00   -0.071486\n",
      "1970-01-01 00:00:00.000000027+00:00   -0.025443\n",
      "1970-01-01 00:00:00.000000028+00:00    0.028497\n",
      "1970-01-01 00:00:00.000000029+00:00   -0.044250\n",
      "1970-01-01 00:00:00.000000030+00:00    0.029999\n",
      "1970-01-01 00:00:00.000000031+00:00    0.015765\n",
      "1970-01-01 00:00:00.000000032+00:00    0.011207\n",
      "1970-01-01 00:00:00.000000033+00:00   -0.000477\n",
      "1970-01-01 00:00:00.000000034+00:00    0.011059\n",
      "1970-01-01 00:00:00.000000035+00:00    0.013406\n",
      "1970-01-01 00:00:00.000000036+00:00    0.021754\n",
      "1970-01-01 00:00:00.000000037+00:00    0.073374\n",
      "1970-01-01 00:00:00.000000038+00:00   -0.011262\n",
      "1970-01-01 00:00:00.000000039+00:00   -0.016560\n",
      "1970-01-01 00:00:00.000000040+00:00    0.011638\n",
      "1970-01-01 00:00:00.000000041+00:00    0.022462\n",
      "1970-01-01 00:00:00.000000042+00:00    0.003984\n",
      "1970-01-01 00:00:00.000000043+00:00    0.005233\n",
      "1970-01-01 00:00:00.000000044+00:00   -0.027219\n",
      "1970-01-01 00:00:00.000000045+00:00    0.012465\n",
      "1970-01-01 00:00:00.000000046+00:00   -0.042091\n",
      "1970-01-01 00:00:00.000000047+00:00   -0.048023\n",
      "1970-01-01 00:00:00.000000048+00:00    0.031190\n",
      "1970-01-01 00:00:00.000000049+00:00   -0.007811\n",
      "1970-01-01 00:00:00.000000050+00:00    0.006504\n",
      "1970-01-01 00:00:00.000000051+00:00    0.014513\n",
      "1970-01-01 00:00:00.000000052+00:00   -0.011580\n",
      "1970-01-01 00:00:00.000000053+00:00   -0.014159\n",
      "1970-01-01 00:00:00.000000054+00:00   -0.009068\n",
      "1970-01-01 00:00:00.000000055+00:00   -0.066680\n",
      "1970-01-01 00:00:00.000000056+00:00   -0.028729\n",
      "1970-01-01 00:00:00.000000057+00:00   -0.073878\n",
      "1970-01-01 00:00:00.000000058+00:00   -0.100059\n",
      "1970-01-01 00:00:00.000000059+00:00    0.523309\n",
      "Name: daily_return, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: 0.00220\n",
      "   Std return : 0.07516\n",
      "   Sharpe     : 0.46510\n",
      " Rolling window_17: 2024-01-06 to 2024-11-06\n",
      " Window 17\n",
      "  Train window: 2024-01-06 to 2024-07-06 — 182 days\n",
      "  Val window  : 2024-07-07 to 2024-09-06   — 61 days\n",
      "  Trade window: 2024-09-07 to 2024-11-06 — 60 days\n",
      "count    60.000000\n",
      "mean      0.000386\n",
      "std       0.030620\n",
      "min      -0.072498\n",
      "25%      -0.017187\n",
      "50%      -0.000710\n",
      "75%       0.015097\n",
      "max       0.119901\n",
      "Name: close, dtype: float64\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1403 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1124         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032815835 |\n",
      "|    clip_fraction        | 0.0334       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.014008045 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35           |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 69           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1122        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004440763 |\n",
      "|    clip_fraction        | 0.0191      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | -0.0085603  |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35          |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00173    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 64.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1108         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00501619   |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.0006842613 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.6         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 71.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1112         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005437743  |\n",
      "|    clip_fraction        | 0.0472       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.0018849969 |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.6         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 74.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1099        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003829101 |\n",
      "|    clip_fraction        | 0.0381      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.00631088  |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 64.7        |\n",
      "-----------------------------------------\n",
      "ppo Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 1.60 | Asset: 1,015,962.00\n",
      "[Validation] Step 2 | Reward: 1.71 | Asset: 1,017,127.80\n",
      "[Validation] Step 3 | Reward: 2.08 | Asset: 1,020,803.71\n",
      "[Validation] Step 4 | Reward: 2.07 | Asset: 1,020,724.23\n",
      "[Validation] Step 5 | Reward: 3.07 | Asset: 1,030,689.13\n",
      "[Validation] Step 57 | Reward: -13.95 | Asset: 860,485.21\n",
      "[Validation] Step 58 | Reward: -16.52 | Asset: 834,802.13\n",
      "[Validation] Step 59 | Reward: -15.79 | Asset: 842,099.54\n",
      "[Validation] Step 60 | Reward: -18.30 | Asset: 817,000.87\n",
      "[Validation] Step 61 | Reward: -18.30 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(860485.2102273854), np.float64(834802.1266297076), np.float64(842099.5378466906), np.float64(817000.8720513762), 1000000.0]\n",
      "[DEBUG] total reward: -18.29991277103545\n",
      "ppo Account Value Range: 1000000.00 to 1000000.00\n",
      "a2c Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 1.45 | Asset: 1,014,470.81\n",
      "[Validation] Step 2 | Reward: 3.72 | Asset: 1,037,172.27\n",
      "[Validation] Step 3 | Reward: 3.17 | Asset: 1,031,661.72\n",
      "[Validation] Step 4 | Reward: 2.51 | Asset: 1,025,100.40\n",
      "[Validation] Step 5 | Reward: 3.44 | Asset: 1,034,436.97\n",
      "[Validation] Step 57 | Reward: 15.46 | Asset: 1,154,553.84\n",
      "[Validation] Step 58 | Reward: 12.40 | Asset: 1,123,982.87\n",
      "[Validation] Step 59 | Reward: 13.30 | Asset: 1,132,965.46\n",
      "[Validation] Step 60 | Reward: 9.97 | Asset: 1,099,670.93\n",
      "[Validation] Step 61 | Reward: 9.97 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(1154553.8359022397), np.float64(1123982.8729975002), np.float64(1132965.4636972588), np.float64(1099670.9261965912), 1000000.0]\n",
      "[DEBUG] total reward: 9.967092318460345\n",
      "a2c Account Value Range: 1000000.00 to 1000000.00\n",
      "ddpg Account Memory Sample: [1000000.0]\n",
      "Is Model Trained? Yes\n",
      "[Validation] Step 1 | Reward: 1.45 | Asset: 1,014,470.81\n",
      "[Validation] Step 2 | Reward: 3.72 | Asset: 1,037,172.27\n",
      "[Validation] Step 3 | Reward: 3.17 | Asset: 1,031,661.72\n",
      "[Validation] Step 4 | Reward: 2.51 | Asset: 1,025,100.40\n",
      "[Validation] Step 5 | Reward: 3.44 | Asset: 1,034,436.97\n",
      "[Validation] Step 57 | Reward: 5.56 | Asset: 1,055,568.48\n",
      "[Validation] Step 58 | Reward: 2.76 | Asset: 1,027,613.68\n",
      "[Validation] Step 59 | Reward: 3.58 | Asset: 1,035,827.57\n",
      "[Validation] Step 60 | Reward: 0.54 | Asset: 1,005,382.27\n",
      "[Validation] Step 61 | Reward: 0.54 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 61\n",
      "[DEBUG] Last 5 values: [np.float64(1055568.4817229998), np.float64(1027613.681723), np.float64(1035827.571723), np.float64(1005382.271723), 1000000.0]\n",
      "[DEBUG] total reward: 0.5382271409034729\n",
      "ddpg Account Value Range: 1000000.00 to 1000000.00\n",
      "[TRADE] Step 1 | Reward: 0.00 | Asset: 1,000,000.00\n",
      "[TRADE] Step 2 | Reward: 3.90 | Asset: 1,038,998.13\n",
      "[TRADE] Step 3 | Reward: 4.97 | Asset: 1,049,689.95\n",
      "[TRADE] Step 4 | Reward: 4.41 | Asset: 1,044,085.09\n",
      "[TRADE] Step 5 | Reward: 4.40 | Asset: 1,043,980.71\n",
      "[TRADE] Step 56 | Reward: 2.61 | Asset: 1,026,100.62\n",
      "[TRADE] Step 57 | Reward: 2.61 | Asset: 1,026,099.55\n",
      "[TRADE] Step 58 | Reward: 1.30 | Asset: 1,013,039.54\n",
      "[TRADE] Step 59 | Reward: 2.14 | Asset: 1,021,353.24\n",
      "[TRADE] Step 60 | Reward: 2.14 | Asset: 1,000,000.00\n",
      "[DEBUG] account_memory length: 60\n",
      "[DEBUG] Last 5 values: [np.float64(1026100.6161077702), np.float64(1026099.5457474776), np.float64(1013039.5393614774), np.float64(1021353.2357849848), 1000000.0]\n",
      "[DEBUG] total reward: 2.1353239526288235\n",
      "✅ Best model: PPO with Sharpe 0.1311\n",
      "   daily_returns: date\n",
      "1970-01-01 00:00:00+00:00                       NaN\n",
      "1970-01-01 00:00:00.000000001+00:00    3.899813e-02\n",
      "1970-01-01 00:00:00.000000002+00:00    1.029051e-02\n",
      "1970-01-01 00:00:00.000000003+00:00   -5.339543e-03\n",
      "1970-01-01 00:00:00.000000004+00:00   -9.997143e-05\n",
      "1970-01-01 00:00:00.000000005+00:00    0.000000e+00\n",
      "1970-01-01 00:00:00.000000006+00:00    0.000000e+00\n",
      "1970-01-01 00:00:00.000000007+00:00    0.000000e+00\n",
      "1970-01-01 00:00:00.000000008+00:00    0.000000e+00\n",
      "1970-01-01 00:00:00.000000009+00:00    4.395716e-03\n",
      "1970-01-01 00:00:00.000000010+00:00    5.081880e-03\n",
      "1970-01-01 00:00:00.000000011+00:00    2.193443e-02\n",
      "1970-01-01 00:00:00.000000012+00:00    2.462716e-02\n",
      "1970-01-01 00:00:00.000000013+00:00    1.647201e-02\n",
      "1970-01-01 00:00:00.000000014+00:00   -1.201962e-02\n",
      "1970-01-01 00:00:00.000000015+00:00    1.866398e-02\n",
      "1970-01-01 00:00:00.000000016+00:00    5.089100e-03\n",
      "1970-01-01 00:00:00.000000017+00:00   -2.520571e-02\n",
      "1970-01-01 00:00:00.000000018+00:00    1.817702e-02\n",
      "1970-01-01 00:00:00.000000019+00:00    2.271720e-02\n",
      "1970-01-01 00:00:00.000000020+00:00   -7.138808e-03\n",
      "1970-01-01 00:00:00.000000021+00:00   -6.255133e-03\n",
      "1970-01-01 00:00:00.000000022+00:00   -2.083419e-02\n",
      "1970-01-01 00:00:00.000000023+00:00   -5.931251e-02\n",
      "1970-01-01 00:00:00.000000024+00:00   -3.416762e-02\n",
      "1970-01-01 00:00:00.000000025+00:00   -4.949677e-03\n",
      "1970-01-01 00:00:00.000000026+00:00    2.476268e-02\n",
      "1970-01-01 00:00:00.000000027+00:00    9.093385e-07\n",
      "1970-01-01 00:00:00.000000028+00:00    1.146395e-02\n",
      "1970-01-01 00:00:00.000000029+00:00   -4.540480e-03\n",
      "1970-01-01 00:00:00.000000030+00:00    4.382771e-03\n",
      "1970-01-01 00:00:00.000000031+00:00   -2.634461e-02\n",
      "1970-01-01 00:00:00.000000032+00:00   -1.870082e-03\n",
      "1970-01-01 00:00:00.000000033+00:00    3.251318e-02\n",
      "1970-01-01 00:00:00.000000034+00:00   -9.610168e-05\n",
      "1970-01-01 00:00:00.000000035+00:00    0.000000e+00\n",
      "1970-01-01 00:00:00.000000036+00:00    0.000000e+00\n",
      "1970-01-01 00:00:00.000000037+00:00    0.000000e+00\n",
      "1970-01-01 00:00:00.000000038+00:00    3.650421e-03\n",
      "1970-01-01 00:00:00.000000039+00:00   -4.673023e-05\n",
      "1970-01-01 00:00:00.000000040+00:00    8.472942e-04\n",
      "1970-01-01 00:00:00.000000041+00:00   -5.612080e-04\n",
      "1970-01-01 00:00:00.000000042+00:00    9.327238e-03\n",
      "1970-01-01 00:00:00.000000043+00:00   -1.303151e-03\n",
      "1970-01-01 00:00:00.000000044+00:00   -1.498041e-04\n",
      "1970-01-01 00:00:00.000000045+00:00   -1.239314e-02\n",
      "1970-01-01 00:00:00.000000046+00:00    2.194864e-02\n",
      "1970-01-01 00:00:00.000000047+00:00   -2.106465e-02\n",
      "1970-01-01 00:00:00.000000048+00:00    6.375328e-03\n",
      "1970-01-01 00:00:00.000000049+00:00   -9.988646e-05\n",
      "1970-01-01 00:00:00.000000050+00:00    5.648273e-03\n",
      "1970-01-01 00:00:00.000000051+00:00    8.794891e-03\n",
      "1970-01-01 00:00:00.000000052+00:00   -1.484245e-03\n",
      "1970-01-01 00:00:00.000000053+00:00   -2.940564e-02\n",
      "1970-01-01 00:00:00.000000054+00:00   -7.967136e-03\n",
      "1970-01-01 00:00:00.000000055+00:00   -1.430822e-04\n",
      "1970-01-01 00:00:00.000000056+00:00   -1.043134e-06\n",
      "1970-01-01 00:00:00.000000057+00:00   -1.272782e-02\n",
      "1970-01-01 00:00:00.000000058+00:00    8.206685e-03\n",
      "1970-01-01 00:00:00.000000059+00:00   -2.090681e-02\n",
      "Name: daily_return, dtype: float64\n",
      " Sharpe Debug:\n",
      "   Mean return: 0.00013\n",
      "   Std return : 0.01648\n",
      "   Sharpe     : 0.12961\n",
      "Metrics saved to ../results/crypto_metrics.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>window</th>\n",
       "      <th>train_start</th>\n",
       "      <th>train_end</th>\n",
       "      <th>val_start</th>\n",
       "      <th>val_end</th>\n",
       "      <th>trade_start</th>\n",
       "      <th>trade_end</th>\n",
       "      <th>sharpe_ratio</th>\n",
       "      <th>min_account_value</th>\n",
       "      <th>max_account_value</th>\n",
       "      <th>total_return</th>\n",
       "      <th>volatility</th>\n",
       "      <th>max_drawdown</th>\n",
       "      <th>initial_acc_val</th>\n",
       "      <th>final_acc_val</th>\n",
       "      <th>ppo</th>\n",
       "      <th>a2c</th>\n",
       "      <th>ddpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PPO</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>2020-09-06</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>2020-11-06</td>\n",
       "      <td>0.292348</td>\n",
       "      <td>973895.471588</td>\n",
       "      <td>1.281342e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033176</td>\n",
       "      <td>0.219568</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.181776</td>\n",
       "      <td>0.061938</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2C</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>2020-12-07</td>\n",
       "      <td>2021-02-06</td>\n",
       "      <td>0.996566</td>\n",
       "      <td>941121.092120</td>\n",
       "      <td>2.113528e+06</td>\n",
       "      <td>0.045943</td>\n",
       "      <td>0.080410</td>\n",
       "      <td>0.526857</td>\n",
       "      <td>9.560753e+05</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.196316</td>\n",
       "      <td>0.595186</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DDPG</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>2021-03-06</td>\n",
       "      <td>2021-03-07</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>0.127618</td>\n",
       "      <td>974403.366587</td>\n",
       "      <td>1.249676e+06</td>\n",
       "      <td>-0.027702</td>\n",
       "      <td>0.040171</td>\n",
       "      <td>0.220275</td>\n",
       "      <td>1.028491e+06</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.214245</td>\n",
       "      <td>0.294001</td>\n",
       "      <td>0.334373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DDPG</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>2021-06-06</td>\n",
       "      <td>2021-06-07</td>\n",
       "      <td>2021-08-06</td>\n",
       "      <td>0.443704</td>\n",
       "      <td>701737.651372</td>\n",
       "      <td>1.109794e+06</td>\n",
       "      <td>0.008581</td>\n",
       "      <td>0.049762</td>\n",
       "      <td>0.280717</td>\n",
       "      <td>9.914921e+05</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.067216</td>\n",
       "      <td>0.459945</td>\n",
       "      <td>0.649386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPO</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>2021-07-07</td>\n",
       "      <td>2021-09-06</td>\n",
       "      <td>2021-09-07</td>\n",
       "      <td>2021-11-06</td>\n",
       "      <td>0.297967</td>\n",
       "      <td>857807.767641</td>\n",
       "      <td>1.222314e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036967</td>\n",
       "      <td>0.181880</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.676045</td>\n",
       "      <td>0.589780</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DDPG</td>\n",
       "      <td>6</td>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>2021-10-06</td>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>2022-02-06</td>\n",
       "      <td>0.423419</td>\n",
       "      <td>557201.449980</td>\n",
       "      <td>1.013008e+06</td>\n",
       "      <td>-0.012841</td>\n",
       "      <td>0.070091</td>\n",
       "      <td>0.449954</td>\n",
       "      <td>1.013008e+06</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.204136</td>\n",
       "      <td>0.344792</td>\n",
       "      <td>0.367173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DDPG</td>\n",
       "      <td>7</td>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>2022-03-06</td>\n",
       "      <td>2022-03-07</td>\n",
       "      <td>2022-05-06</td>\n",
       "      <td>0.176861</td>\n",
       "      <td>967539.963020</td>\n",
       "      <td>1.353944e+06</td>\n",
       "      <td>-0.008389</td>\n",
       "      <td>0.031567</td>\n",
       "      <td>0.261417</td>\n",
       "      <td>1.008460e+06</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.359224</td>\n",
       "      <td>0.275819</td>\n",
       "      <td>0.457442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PPO</td>\n",
       "      <td>8</td>\n",
       "      <td>2021-10-06</td>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>2022-06-06</td>\n",
       "      <td>2022-06-07</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>0.526776</td>\n",
       "      <td>860060.895047</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>0.030458</td>\n",
       "      <td>0.023295</td>\n",
       "      <td>0.110382</td>\n",
       "      <td>9.704425e+05</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.530598</td>\n",
       "      <td>0.523714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A2C</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>2022-07-06</td>\n",
       "      <td>2022-07-07</td>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>2022-11-06</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1.003567e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.178617</td>\n",
       "      <td>2.038686</td>\n",
       "      <td>0.528610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DDPG</td>\n",
       "      <td>10</td>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>2022-10-07</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>0.215692</td>\n",
       "      <td>976432.823824</td>\n",
       "      <td>1.407335e+06</td>\n",
       "      <td>-0.022254</td>\n",
       "      <td>0.040292</td>\n",
       "      <td>0.289437</td>\n",
       "      <td>1.022761e+06</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.245248</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.331988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PPO</td>\n",
       "      <td>11</td>\n",
       "      <td>2022-07-06</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>2023-05-06</td>\n",
       "      <td>0.438971</td>\n",
       "      <td>907772.959180</td>\n",
       "      <td>1.110318e+06</td>\n",
       "      <td>0.022770</td>\n",
       "      <td>0.024080</td>\n",
       "      <td>0.109089</td>\n",
       "      <td>9.777367e+05</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.251871</td>\n",
       "      <td>0.195628</td>\n",
       "      <td>0.240791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DDPG</td>\n",
       "      <td>12</td>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>2023-06-06</td>\n",
       "      <td>2023-06-07</td>\n",
       "      <td>2023-08-06</td>\n",
       "      <td>0.135172</td>\n",
       "      <td>918001.297308</td>\n",
       "      <td>1.114570e+06</td>\n",
       "      <td>-0.001331</td>\n",
       "      <td>0.019834</td>\n",
       "      <td>0.102793</td>\n",
       "      <td>1.001333e+06</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.141676</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.203518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DDPG</td>\n",
       "      <td>13</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-07-06</td>\n",
       "      <td>2023-07-07</td>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>2023-09-07</td>\n",
       "      <td>2023-11-06</td>\n",
       "      <td>0.434605</td>\n",
       "      <td>958385.991000</td>\n",
       "      <td>1.348225e+06</td>\n",
       "      <td>0.013367</td>\n",
       "      <td>0.038348</td>\n",
       "      <td>0.258284</td>\n",
       "      <td>9.868092e+05</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.168213</td>\n",
       "      <td>0.198669</td>\n",
       "      <td>0.228589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A2C</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>2023-10-06</td>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>2023-12-06</td>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>2024-02-06</td>\n",
       "      <td>-0.125731</td>\n",
       "      <td>958663.615288</td>\n",
       "      <td>1.068396e+06</td>\n",
       "      <td>-0.020140</td>\n",
       "      <td>0.019450</td>\n",
       "      <td>0.064018</td>\n",
       "      <td>1.020554e+06</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.182297</td>\n",
       "      <td>0.317672</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A2C</td>\n",
       "      <td>15</td>\n",
       "      <td>2023-07-06</td>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>2024-03-06</td>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>0.272671</td>\n",
       "      <td>851524.885585</td>\n",
       "      <td>1.054888e+06</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>0.035342</td>\n",
       "      <td>0.192782</td>\n",
       "      <td>1.000305e+06</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.058101</td>\n",
       "      <td>0.307662</td>\n",
       "      <td>-0.568069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DDPG</td>\n",
       "      <td>16</td>\n",
       "      <td>2023-10-06</td>\n",
       "      <td>2024-04-06</td>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>2024-06-06</td>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>0.465098</td>\n",
       "      <td>656465.575660</td>\n",
       "      <td>1.005217e+06</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>0.075159</td>\n",
       "      <td>0.346942</td>\n",
       "      <td>1.000288e+06</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>-0.069547</td>\n",
       "      <td>-0.139020</td>\n",
       "      <td>0.117118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PPO</td>\n",
       "      <td>17</td>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>2024-07-06</td>\n",
       "      <td>2024-07-07</td>\n",
       "      <td>2024-09-06</td>\n",
       "      <td>2024-09-07</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>0.129613</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1.151751e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016484</td>\n",
       "      <td>0.131757</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.131117</td>\n",
       "      <td>0.104737</td>\n",
       "      <td>0.092119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent  window train_start   train_end   val_start     val_end trade_start  \\\n",
       "0    PPO       1  2020-01-06  2020-07-06  2020-07-07  2020-09-06  2020-09-07   \n",
       "1    A2C       2  2020-04-06  2020-10-06  2020-10-07  2020-12-06  2020-12-07   \n",
       "2   DDPG       3  2020-07-06  2021-01-06  2021-01-07  2021-03-06  2021-03-07   \n",
       "3   DDPG       4  2020-10-06  2021-04-06  2021-04-07  2021-06-06  2021-06-07   \n",
       "4    PPO       5  2021-01-06  2021-07-06  2021-07-07  2021-09-06  2021-09-07   \n",
       "5   DDPG       6  2021-04-06  2021-10-06  2021-10-07  2021-12-06  2021-12-07   \n",
       "6   DDPG       7  2021-07-06  2022-01-06  2022-01-07  2022-03-06  2022-03-07   \n",
       "7    PPO       8  2021-10-06  2022-04-06  2022-04-07  2022-06-06  2022-06-07   \n",
       "8    A2C       9  2022-01-06  2022-07-06  2022-07-07  2022-09-06  2022-09-07   \n",
       "9   DDPG      10  2022-04-06  2022-10-06  2022-10-07  2022-12-06  2022-12-07   \n",
       "10   PPO      11  2022-07-06  2023-01-06  2023-01-07  2023-03-06  2023-03-07   \n",
       "11  DDPG      12  2022-10-06  2023-04-06  2023-04-07  2023-06-06  2023-06-07   \n",
       "12  DDPG      13  2023-01-06  2023-07-06  2023-07-07  2023-09-06  2023-09-07   \n",
       "13   A2C      14  2023-04-06  2023-10-06  2023-10-07  2023-12-06  2023-12-07   \n",
       "14   A2C      15  2023-07-06  2024-01-06  2024-01-07  2024-03-06  2024-03-07   \n",
       "15  DDPG      16  2023-10-06  2024-04-06  2024-04-07  2024-06-06  2024-06-07   \n",
       "16   PPO      17  2024-01-06  2024-07-06  2024-07-07  2024-09-06  2024-09-07   \n",
       "\n",
       "     trade_end  sharpe_ratio  min_account_value  max_account_value  \\\n",
       "0   2020-11-06      0.292348      973895.471588       1.281342e+06   \n",
       "1   2021-02-06      0.996566      941121.092120       2.113528e+06   \n",
       "2   2021-05-06      0.127618      974403.366587       1.249676e+06   \n",
       "3   2021-08-06      0.443704      701737.651372       1.109794e+06   \n",
       "4   2021-11-06      0.297967      857807.767641       1.222314e+06   \n",
       "5   2022-02-06      0.423419      557201.449980       1.013008e+06   \n",
       "6   2022-05-06      0.176861      967539.963020       1.353944e+06   \n",
       "7   2022-08-06      0.526776      860060.895047       1.000000e+06   \n",
       "8   2022-11-06      0.005150     1000000.000000       1.003567e+06   \n",
       "9   2023-02-06      0.215692      976432.823824       1.407335e+06   \n",
       "10  2023-05-06      0.438971      907772.959180       1.110318e+06   \n",
       "11  2023-08-06      0.135172      918001.297308       1.114570e+06   \n",
       "12  2023-11-06      0.434605      958385.991000       1.348225e+06   \n",
       "13  2024-02-06     -0.125731      958663.615288       1.068396e+06   \n",
       "14  2024-05-06      0.272671      851524.885585       1.054888e+06   \n",
       "15  2024-08-06      0.465098      656465.575660       1.005217e+06   \n",
       "16  2024-11-06      0.129613     1000000.000000       1.151751e+06   \n",
       "\n",
       "    total_return  volatility  max_drawdown  initial_acc_val  final_acc_val  \\\n",
       "0       0.000000    0.033176      0.219568     1.000000e+06      1000000.0   \n",
       "1       0.045943    0.080410      0.526857     9.560753e+05      1000000.0   \n",
       "2      -0.027702    0.040171      0.220275     1.028491e+06      1000000.0   \n",
       "3       0.008581    0.049762      0.280717     9.914921e+05      1000000.0   \n",
       "4       0.000000    0.036967      0.181880     1.000000e+06      1000000.0   \n",
       "5      -0.012841    0.070091      0.449954     1.013008e+06      1000000.0   \n",
       "6      -0.008389    0.031567      0.261417     1.008460e+06      1000000.0   \n",
       "7       0.030458    0.023295      0.110382     9.704425e+05      1000000.0   \n",
       "8       0.000000    0.000660      0.003554     1.000000e+06      1000000.0   \n",
       "9      -0.022254    0.040292      0.289437     1.022761e+06      1000000.0   \n",
       "10      0.022770    0.024080      0.109089     9.777367e+05      1000000.0   \n",
       "11     -0.001331    0.019834      0.102793     1.001333e+06      1000000.0   \n",
       "12      0.013367    0.038348      0.258284     9.868092e+05      1000000.0   \n",
       "13     -0.020140    0.019450      0.064018     1.020554e+06      1000000.0   \n",
       "14     -0.000305    0.035342      0.192782     1.000305e+06      1000000.0   \n",
       "15     -0.000288    0.075159      0.346942     1.000288e+06      1000000.0   \n",
       "16      0.000000    0.016484      0.131757     1.000000e+06      1000000.0   \n",
       "\n",
       "         ppo       a2c      ddpg  \n",
       "0   0.181776  0.061938       NaN  \n",
       "1   0.196316  0.595186       NaN  \n",
       "2   0.214245  0.294001  0.334373  \n",
       "3   0.067216  0.459945  0.649386  \n",
       "4   0.676045  0.589780       NaN  \n",
       "5   0.204136  0.344792  0.367173  \n",
       "6   0.359224  0.275819  0.457442  \n",
       "7   0.530598  0.523714       NaN  \n",
       "8   0.178617  2.038686  0.528610  \n",
       "9   0.245248  0.000501  0.331988  \n",
       "10  0.251871  0.195628  0.240791  \n",
       "11  0.141676  0.186047  0.203518  \n",
       "12  0.168213  0.198669  0.228589  \n",
       "13  0.182297  0.317672       NaN  \n",
       "14  0.058101  0.307662 -0.568069  \n",
       "15 -0.069547 -0.139020  0.117118  \n",
       "16  0.131117  0.104737  0.092119  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Account values saved to: ../results/rolling_account_values.csv\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO, A2C, DDPG\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from finrl.plot.plot import get_daily_return  \n",
    "\n",
    "#  rolling window backtest using three reinforcement learning agents (PPO, A2C, DDPG). \n",
    "account_values_dict = {} # account_values \n",
    "EPISODES = 10\n",
    "performance_log = []\n",
    "\n",
    "for i, (train_start, train_end, val_start, val_end, trade_start, trade_end) in enumerate(windows):\n",
    "\n",
    "    window_name = f\"window_{i+1}\"\n",
    "    print(f\" Rolling {window_name}: {train_start.date()} to {trade_end.date()}\")\n",
    "    \n",
    "    train_data = data_split(df_processed, train_start, train_end)\n",
    "    val_data = data_split(df_processed, val_start, val_end)\n",
    "    trade_data = data_split(df_processed, trade_start, trade_end)\n",
    "\n",
    "    min_days_required = 30\n",
    "\n",
    "    if len(train_data[\"date\"].unique()) < min_days_required:\n",
    "        print(f\"  Skipping Window {i+1} — Train window too short: {len(train_data['date'].unique())} days\")\n",
    "        continue\n",
    "    \n",
    "    if len(val_data[\"date\"].unique()) < min_days_required:\n",
    "        print(f\"  Skipping Window {i+1} — Validation window too short: {len(val_data['date'].unique())} days\")\n",
    "        continue\n",
    "        \n",
    "    val_returns = val_data.groupby(\"date\")[\"close\"].mean().pct_change().dropna()\n",
    "    if val_returns.std() == 0 or val_returns.empty:\n",
    "        print(f\"  Skipping Window {i+1} — No price volatility in validation window.\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    env_train = DummyVecEnv([lambda: CryptoTradingEnv(train_data)])\n",
    "    agent = DRLAgent(env=env_train)\n",
    "\n",
    "    models = {\n",
    "        \"ppo\": agent.train_PPO(total_timesteps=len(train_data)*30, model_kwargs=PPO_model_kwargs),\n",
    "        \"a2c\": agent.train_A2C(total_timesteps=len(train_data)*30, model_kwargs=A2C_model_kwargs),\n",
    "        \"ddpg\": agent.train_DDPG(total_timesteps=int(len(train_data)*30*0.5), model_kwargs=DDPG_model_kwargs)\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_sharpe = -np.inf\n",
    "    val_sharpes = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        env_val = DummyVecEnv([lambda: CryptoTradingEnv(val_data)])\n",
    "\n",
    "        sharpe_metrics = DRLAgent.DRL_prediction(model=model, environment=env_val, evaluate=True)\n",
    "        sharpe = sharpe_metrics[\"sharpe\"]\n",
    "        val_sharpes.append((name, sharpe))\n",
    "\n",
    "        # Debug: print account value\n",
    "        account_vals = env_val.envs[0].asset_memory\n",
    "        if not np.isnan(sharpe) and sharpe > best_sharpe:\n",
    "            best_model = model\n",
    "            best_sharpe = sharpe\n",
    "\n",
    "    env_trade = DummyVecEnv([lambda: CryptoTradingEnv(trade_data)])\n",
    "    val_sharpe_dict = {name: sharpe for name, sharpe in val_sharpes}\n",
    "\n",
    "    if best_model is not None:\n",
    "        startdt = datetime.strptime(trade_start.date(), \"%Y-%m-%d\")\n",
    "        df_result = DRLAgent.DRL_prediction(model=best_model, environment=env_trade, start_date=startdt)\n",
    "        account_values_series = df_result[\"account_value\"].reset_index(drop=True)\n",
    "        account_values_dict[window_name] = account_values_series\n",
    "\n",
    "        print(f\"✅ Best model: {best_model.__class__.__name__} with Sharpe {best_sharpe:.4f}\")\n",
    "        account_values = df_result[\"account_value\"]\n",
    "      \n",
    "    # get_daily_return: Creates daily returns using pct_change(1) on the account_value column\n",
    "    # Using Time zone localization to UTC — though only needed for other then daily returns\n",
    "    # @ Returns a pandas Series of daily returns, indexed by date for further analysis.\n",
    "        daily_returns = get_daily_return(df_result)  # get_daily_return expects a full df with date\n",
    "        \n",
    "        sharpe = (365**0.5) * daily_returns.mean() / daily_returns.std()\n",
    "        \n",
    "        total_return = account_values.iloc[-1] / account_values.iloc[0] - 1\n",
    "        volatility = daily_returns.std()\n",
    "        max_drawdown = (account_values.cummax() - account_values).max() / account_values.cummax().max()\n",
    "\n",
    "        performance_log.append({\n",
    "                \"agent\": best_model.__class__.__name__,\n",
    "                \"window\": i + 1,\n",
    "                \"train_start\": train_start.date(),\n",
    "                \"train_end\": train_end.date(),\n",
    "                \"val_start\": val_start.date(),\n",
    "                \"val_end\": val_end.date(),\n",
    "                \"trade_start\": trade_start.date(),\n",
    "                \"trade_end\": trade_end.date(),\n",
    "                \"sharpe_ratio\": sharpe,\n",
    "                \"min_account_value\": account_values.min(),\n",
    "                \"max_account_value\": account_values.max(),\n",
    "                \"total_return\": total_return,\n",
    "                \"volatility\": volatility,\n",
    "                \"max_drawdown\": max_drawdown,\n",
    "                \"initial_acc_val\": account_values.iloc[0],\n",
    "                \"final_acc_val\": account_values.iloc[-1],\n",
    "                **val_sharpe_dict\n",
    "            })\n",
    "    else:\n",
    "        print(f\"❌ No valid model selected in window {i+1} — skipping trade step.\")\n",
    "\n",
    "\n",
    "if performance_log:\n",
    "    df_metrics = pd.DataFrame(performance_log)\n",
    "    df_metrics.to_csv(\"../results/crypto_metrics.csv\", index=False)\n",
    "    print(\"Metrics saved to ../results/crypto_metrics.csv\")\n",
    "    display(df_metrics)\n",
    "\n",
    "    df_account_values_all = pd.DataFrame(account_values_dict)\n",
    "    df_account_values_all.to_csv(\"../results/rolling_account_values.csv\", index=False)\n",
    "    print(\"📁 Account values saved to: ../results/rolling_account_values.csv\")\n",
    "    \n",
    "else:\n",
    "    print(\"No results to analyze.\")\n",
    "    print(val_sharpe_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1b61ed-2a05-4450-9ef7-78bdde395598",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## from finrl.plot import get_daily_return\n",
    "\n",
    "account_values = df_result[\"account_value\"]\n",
    "daily_returns = get_daily_return(account_values)\n",
    "\n",
    "sharpe = (252**0.5) * daily_returns.mean() / daily_returns.std()\n",
    "total_return = account_values.iloc[-1] / account_values.iloc[0] - 1\n",
    "volatility = daily_returns.std()\n",
    "max_drawdown = (account_values.cummax() - account_values).max() / account_values.cummax().max()\n",
    "\n",
    "\n",
    "df_final = pd.concat(results)\n",
    "backtest_stats(df_final)\n",
    "backtest_plot(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219cecd3-3bdd-49f5-bc16-fe0f6d6a4dd3",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d3cb56-a777-49c6-932f-e69d148268fd",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
